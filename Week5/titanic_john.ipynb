{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import general purpose libraries\n",
    "\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in the data\n",
    "train_data = pd.read_csv(\"../../datasets/titanic/train.csv\")\n",
    "test_data = pd.read_csv(\"../../datasets/titanic/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So immediately, we can notice quite a few things here:\n",
    "* We are predicting the variable `Survived`, which is a binary 1/0 classification\n",
    "* We have a few different classes on the boat\n",
    "* The names are kinda irregular, we probably want to do something here\n",
    "* Tickets have irregular formatting\n",
    "* Cabins have missing values\n",
    "\n",
    "In short, it looks like we will have some feature engineering to do in order to model this.\n",
    "\n",
    "Let's take a look at the distribution of survival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>549</td>\n",
       "      <td>549</td>\n",
       "      <td>549</td>\n",
       "      <td>549</td>\n",
       "      <td>424</td>\n",
       "      <td>549</td>\n",
       "      <td>549</td>\n",
       "      <td>549</td>\n",
       "      <td>549</td>\n",
       "      <td>68</td>\n",
       "      <td>549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>342</td>\n",
       "      <td>342</td>\n",
       "      <td>342</td>\n",
       "      <td>342</td>\n",
       "      <td>290</td>\n",
       "      <td>342</td>\n",
       "      <td>342</td>\n",
       "      <td>342</td>\n",
       "      <td>342</td>\n",
       "      <td>136</td>\n",
       "      <td>340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          PassengerId  Pclass  Name  Sex  Age  SibSp  Parch  Ticket  Fare  \\\n",
       "Survived                                                                    \n",
       "0                 549     549   549  549  424    549    549     549   549   \n",
       "1                 342     342   342  342  290    342    342     342   342   \n",
       "\n",
       "          Cabin  Embarked  \n",
       "Survived                   \n",
       "0            68       549  \n",
       "1           136       340  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.groupby('Survived').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have 549 that are class 0 (presumably, not survived) and 342 class 1 (presumably, survived). We are probably okay in saying that we have enough of each class that we don't have to do anything special to have enough of each class to make accurate predictions. Let's do a little bit more exploratory analysis to figure out a solid baseline, to figure out if a model presents any real value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived  Sex   \n",
       "0         female     81\n",
       "          male      468\n",
       "1         female    233\n",
       "          male      109\n",
       "Name: PassengerId, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.groupby(['Survived', 'Sex']).count()['PassengerId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived  Pclass\n",
       "0         1          80\n",
       "          2          97\n",
       "          3         372\n",
       "1         1         136\n",
       "          2          87\n",
       "          3         119\n",
       "Name: PassengerId, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.groupby(['Survived', 'Pclass']).count()['PassengerId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived  Embarked\n",
       "0         C            75\n",
       "          Q            47\n",
       "          S           427\n",
       "1         C            93\n",
       "          Q            30\n",
       "          S           217\n",
       "Name: PassengerId, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.groupby(['Survived', 'Embarked']).count()['PassengerId']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like a pretty clear division for survival is the sex of the passenger, as females look like they fared much better. I also may have seen a few notebooks on this dataset and know that this tends to be a pretty standard division...\n",
    "\n",
    "Let's write a function for our baseline of predicting a 1 for female, and 0 for male. Also, we can assess the accuracy and/or any other metric "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline results:\n",
      "0.7867564534231201\n",
      "[[468  81]\n",
      " [109 233]]\n"
     ]
    }
   ],
   "source": [
    "# note that you need to turn the pandas dataframe into a numpy array\n",
    "train_data_array = train_data.values\n",
    "train_data_array.shape\n",
    "predictions = np.array([train_data_array[x][4] == \"female\" for x in range(train_data_array.shape[0])]).astype(\"int\")\n",
    "baseline_accuracy = accuracy_score(y_pred=predictions, y_true=train_data.Survived)\n",
    "print(\"Baseline results:\")\n",
    "print(baseline_accuracy)\n",
    "print(confusion_matrix(y_pred=predictions, y_true=train_data.Survived))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so with our current train/test split, we see that we are 78.7% accurate if we just guess based on gender. So if anything isn't better than this, our model is pretty much useless. We can note here that we have more false positives than false negatives.\n",
    "\n",
    "With a baseline under our belt, we can look into doing some feature engineering for machine learning.\n",
    "\n",
    "The first thing we will do is take a look into the tickets, and see if there appears to be any sort of patterns here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             A/5 21171\n",
       "1              PC 17599\n",
       "2      STON/O2. 3101282\n",
       "3                113803\n",
       "4                373450\n",
       "5                330877\n",
       "6                 17463\n",
       "7                349909\n",
       "8                347742\n",
       "9                237736\n",
       "10              PP 9549\n",
       "11               113783\n",
       "12            A/5. 2151\n",
       "13               347082\n",
       "14               350406\n",
       "15               248706\n",
       "16               382652\n",
       "17               244373\n",
       "18               345763\n",
       "19                 2649\n",
       "20               239865\n",
       "21               248698\n",
       "22               330923\n",
       "23               113788\n",
       "24               349909\n",
       "25               347077\n",
       "26                 2631\n",
       "27                19950\n",
       "28               330959\n",
       "29               349216\n",
       "             ...       \n",
       "861               28134\n",
       "862               17466\n",
       "863            CA. 2343\n",
       "864              233866\n",
       "865              236852\n",
       "866       SC/PARIS 2149\n",
       "867            PC 17590\n",
       "868              345777\n",
       "869              347742\n",
       "870              349248\n",
       "871               11751\n",
       "872                 695\n",
       "873              345765\n",
       "874           P/PP 3381\n",
       "875                2667\n",
       "876                7534\n",
       "877              349212\n",
       "878              349217\n",
       "879               11767\n",
       "880              230433\n",
       "881              349257\n",
       "882                7552\n",
       "883    C.A./SOTON 34068\n",
       "884     SOTON/OQ 392076\n",
       "885              382652\n",
       "886              211536\n",
       "887              112053\n",
       "888          W./C. 6607\n",
       "889              111369\n",
       "890              370376\n",
       "Name: Ticket, Length: 891, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.Ticket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks all of these have one numeric term, and then one optional character string. We can separate these out into two vectors. The first one will be binary for the presence of the character string, and the second will just have the number of digits of the numeric part. I'm operating under the assumption that each individual ticket name shouldn't be treated as a numeric and they all don't mean anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ticket_array = train_data.Ticket \n",
    "ticket_array = ticket_array.astype(\"str\")\n",
    "\n",
    "def return_splits(single_string):\n",
    "\n",
    "    if len(single_string.split(\" \")) == 1:\n",
    "        ticket_prefix, ticket_num_digits = 0, len(single_string.split(\" \")[0])\n",
    "    else: \n",
    "        ticket_prefix, ticket_num_digits = 1, len(single_string.split(\" \")[1])\n",
    "        \n",
    "    return(ticket_prefix, ticket_num_digits)\n",
    "\n",
    "# probably a more efficient way to do this than a loop but that's what we'll do for now\n",
    "# confusing with python multiple assignments on how to get this to have 'apply'-like functionality\n",
    "def create_new_ticket_cols(ticket_array):\n",
    "    ticket_prefix, ticket_num_digits = np.zeros(ticket_array.shape[0]), np.zeros(ticket_array.shape[0])\n",
    "    for i in range(ticket_array.shape[0]):\n",
    "        ticket_prefix[i], ticket_num_digits[i] = return_splits(ticket_array[i])\n",
    "\n",
    "    # numpy is particular about dimensions\n",
    "    ticket_prefix = ticket_prefix.reshape(-1, 1)\n",
    "    ticket_num_digits = ticket_num_digits.reshape(-1, 1)\n",
    "    return(ticket_prefix, ticket_num_digits)\n",
    "\n",
    "def ticket_preprocessing_pipeline(data, col = 'Ticket'):\n",
    "    ticket_array = data[col]\n",
    "    ticket_array = ticket_array.astype(\"str\")\n",
    "    ticket_prefix, ticket_num_digits = create_new_ticket_cols(ticket_array)\n",
    "    data['ticket_prefix'] = ticket_prefix\n",
    "    data['ticket_num_digits'] = ticket_num_digits\n",
    "    \n",
    "    # need to keep in mind that we still have the original ticket column\n",
    "    # need to get rid of this afterwards\n",
    "    return(data)\n",
    "\n",
    "train_data_new, test_data_new = ticket_preprocessing_pipeline(train_data), ticket_preprocessing_pipeline(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>ticket_prefix</th>\n",
       "      <th>ticket_num_digits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  ticket_prefix  \\\n",
       "0      0         A/5 21171   7.2500   NaN        S            1.0   \n",
       "1      0          PC 17599  71.2833   C85        C            1.0   \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S            1.0   \n",
       "3      0            113803  53.1000  C123        S            0.0   \n",
       "4      0            373450   8.0500   NaN        S            0.0   \n",
       "\n",
       "   ticket_num_digits  \n",
       "0                5.0  \n",
       "1                5.0  \n",
       "2                7.0  \n",
       "3                6.0  \n",
       "4                6.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                Braund, Mr. Owen Harris\n",
       "1      Cumings, Mrs. John Bradley (Florence Briggs Th...\n",
       "2                                 Heikkinen, Miss. Laina\n",
       "3           Futrelle, Mrs. Jacques Heath (Lily May Peel)\n",
       "4                               Allen, Mr. William Henry\n",
       "5                                       Moran, Mr. James\n",
       "6                                McCarthy, Mr. Timothy J\n",
       "7                         Palsson, Master. Gosta Leonard\n",
       "8      Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)\n",
       "9                    Nasser, Mrs. Nicholas (Adele Achem)\n",
       "10                       Sandstrom, Miss. Marguerite Rut\n",
       "11                              Bonnell, Miss. Elizabeth\n",
       "12                        Saundercock, Mr. William Henry\n",
       "13                           Andersson, Mr. Anders Johan\n",
       "14                  Vestrom, Miss. Hulda Amanda Adolfina\n",
       "15                      Hewlett, Mrs. (Mary D Kingcome) \n",
       "16                                  Rice, Master. Eugene\n",
       "17                          Williams, Mr. Charles Eugene\n",
       "18     Vander Planke, Mrs. Julius (Emelia Maria Vande...\n",
       "19                               Masselmani, Mrs. Fatima\n",
       "20                                  Fynney, Mr. Joseph J\n",
       "21                                 Beesley, Mr. Lawrence\n",
       "22                           McGowan, Miss. Anna \"Annie\"\n",
       "23                          Sloper, Mr. William Thompson\n",
       "24                         Palsson, Miss. Torborg Danira\n",
       "25     Asplund, Mrs. Carl Oscar (Selma Augusta Emilia...\n",
       "26                               Emir, Mr. Farred Chehab\n",
       "27                        Fortune, Mr. Charles Alexander\n",
       "28                         O'Dwyer, Miss. Ellen \"Nellie\"\n",
       "29                                   Todoroff, Mr. Lalio\n",
       "                             ...                        \n",
       "861                          Giles, Mr. Frederick Edward\n",
       "862    Swift, Mrs. Frederick Joel (Margaret Welles Ba...\n",
       "863                    Sage, Miss. Dorothy Edith \"Dolly\"\n",
       "864                               Gill, Mr. John William\n",
       "865                             Bystrom, Mrs. (Karolina)\n",
       "866                         Duran y More, Miss. Asuncion\n",
       "867                 Roebling, Mr. Washington Augustus II\n",
       "868                          van Melkebeke, Mr. Philemon\n",
       "869                      Johnson, Master. Harold Theodor\n",
       "870                                    Balkic, Mr. Cerin\n",
       "871     Beckwith, Mrs. Richard Leonard (Sallie Monypeny)\n",
       "872                             Carlsson, Mr. Frans Olof\n",
       "873                          Vander Cruyssen, Mr. Victor\n",
       "874                Abelson, Mrs. Samuel (Hannah Wizosky)\n",
       "875                     Najib, Miss. Adele Kiamie \"Jane\"\n",
       "876                        Gustafsson, Mr. Alfred Ossian\n",
       "877                                 Petroff, Mr. Nedelio\n",
       "878                                   Laleff, Mr. Kristo\n",
       "879        Potter, Mrs. Thomas Jr (Lily Alexenia Wilson)\n",
       "880         Shelley, Mrs. William (Imanita Parrish Hall)\n",
       "881                                   Markun, Mr. Johann\n",
       "882                         Dahlberg, Miss. Gerda Ulrika\n",
       "883                        Banfield, Mr. Frederick James\n",
       "884                               Sutehall, Mr. Henry Jr\n",
       "885                 Rice, Mrs. William (Margaret Norton)\n",
       "886                                Montvila, Rev. Juozas\n",
       "887                         Graham, Miss. Margaret Edith\n",
       "888             Johnston, Miss. Catherine Helen \"Carrie\"\n",
       "889                                Behr, Mr. Karl Howell\n",
       "890                                  Dooley, Mr. Patrick\n",
       "Name: Name, Length: 891, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.Name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So from here, it looks like all of our names have different lengths. It's not immediately clear without more digging, but right now it ~looks~ like all the \"titles\" have a period afterwards. So let's create a feature column with the title from the name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# single_string = name_array[10]\n",
    "def return_name_splits(single_string):\n",
    "    words = single_string.split(' ')\n",
    "    boolean_words = ['.' in word for word in words]\n",
    "    # some logic, to catch the cases where we might not have a title or might have multiple\n",
    "    if any(boolean_words):\n",
    "        indexes = [i for i, x in enumerate(boolean_words) if x]\n",
    "        if len(indexes) > 1:\n",
    "            val_back = \"Multi\"\n",
    "        val_back = words[indexes[0]]\n",
    "    else:\n",
    "        val_back = \"None\"\n",
    "    return(val_back)\n",
    "\n",
    "# probably a more efficient way to do this than a loop but that's what we'll do for now\n",
    "# confusing with python multiple assignments on how to get this to have 'apply'-like functionality\n",
    "def create_new_title_cols(name_array):\n",
    "    title_array = np.zeros(name_array.shape[0]).astype(\"str\")\n",
    "    for i in range(name_array.shape[0]):\n",
    "        title_array[i] = return_name_splits(name_array[i])\n",
    "\n",
    "    # numpy is particular about dimensions\n",
    "    title_array = title_array.reshape(-1, 1)\n",
    "    return(title_array)\n",
    "\n",
    "# we have a pd dataframe here so it doesn't really work\n",
    "# need to rethink this pipeline bc numpy, pandas differences\n",
    "def title_preprocessing_pipeline(data, col = 'Name'):\n",
    "    name_array = data[col]\n",
    "    name_array = name_array.astype(\"str\")\n",
    "    titles = create_new_title_cols(name_array)\n",
    "    data['title'] = titles\n",
    "    \n",
    "    # need to keep in mind that we still have the originalname column\n",
    "    # need to get rid of this afterwards\n",
    "    return(data)\n",
    "\n",
    "train_data_new, test_data_new = title_preprocessing_pipeline(train_data_new), title_preprocessing_pipeline(test_data_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>ticket_prefix</th>\n",
       "      <th>ticket_num_digits</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Mrs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Miss.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Mrs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  ticket_prefix  \\\n",
       "0      0         A/5 21171   7.2500   NaN        S            1.0   \n",
       "1      0          PC 17599  71.2833   C85        C            1.0   \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S            1.0   \n",
       "3      0            113803  53.1000  C123        S            0.0   \n",
       "4      0            373450   8.0500   NaN        S            0.0   \n",
       "\n",
       "   ticket_num_digits  title  \n",
       "0                5.0    Mr.  \n",
       "1                5.0   Mrs.  \n",
       "2                7.0  Miss.  \n",
       "3                6.0   Mrs.  \n",
       "4                6.0    Mr.  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>ticket_prefix</th>\n",
       "      <th>ticket_num_digits</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Mrs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Mrs.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  ticket_prefix  \\\n",
       "0  34.5      0      0   330911   7.8292   NaN        Q            0.0   \n",
       "1  47.0      1      0   363272   7.0000   NaN        S            0.0   \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q            0.0   \n",
       "3  27.0      0      0   315154   8.6625   NaN        S            0.0   \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S            0.0   \n",
       "\n",
       "   ticket_num_digits title  \n",
       "0                6.0   Mr.  \n",
       "1                6.0  Mrs.  \n",
       "2                6.0   Mr.  \n",
       "3                6.0   Mr.  \n",
       "4                7.0  Mrs.  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to have some sort of treatment of all of these categorical variables if we want to do a logistic regression. A lot of machine algorithms can't handle multi-leveled categorical inputs. We can use one-hot-encoding (lots of columns of 1s and 0s) in order to keep the same fundamental information though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johnb\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(891, 174)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def array_from_pd(item):\n",
    "    return(item.values.astype(\"str\").reshape(-1,1))\n",
    "    \n",
    "title_encoder = OneHotEncoder().fit(array_from_pd(train_data_new.title))\n",
    "sex_encoder = OneHotEncoder().fit(array_from_pd(train_data_new.Sex))\n",
    "Pclass_encoder = OneHotEncoder().fit(array_from_pd(train_data_new.Pclass))\n",
    "Cabin_encoder = OneHotEncoder().fit(array_from_pd(train_data_new.Cabin))\n",
    "Embarked_encoder = OneHotEncoder().fit(array_from_pd(train_data_new.Embarked))\n",
    "\n",
    "def create_onehotencoded_features(data):\n",
    "    # get an appropriate array for all the encoding we have to do\n",
    "    titles_coded = title_encoder.transform(array_from_pd(data.title)).toarray()\n",
    "    sex_coded = sex_encoder.transform(array_from_pd(data.Sex)).toarray()\n",
    "    pclass_coded = Pclass_encoder.transform(array_from_pd(data.Pclass)).toarray()\n",
    "    cabin_coded = Cabin_encoder.transform(array_from_pd(data.Cabin)).toarray()\n",
    "    embarked_coded = Embarked_encoder.transform(array_from_pd(data.Embarked)).toarray()\n",
    "    \n",
    "    # put all the arrays together\n",
    "    all_coded = np.concatenate((titles_coded, sex_coded, pclass_coded, cabin_coded, embarked_coded), axis = 1)\n",
    "    return(all_coded)\n",
    "\n",
    "arr_return = create_onehotencoded_features(train_data_new)\n",
    "arr_return.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point now, we have a super sparse matrix denoting all of our possible categorical variable values. Let's do the same thing for our test data to have consistent preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found unknown categories ['Dona.'] in column 0 during transform",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-a7210988ae53>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0marr_return_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_onehotencoded_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data_new\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-19-121fdd359408>\u001b[0m in \u001b[0;36mcreate_onehotencoded_features\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcreate_onehotencoded_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;31m# get an appropriate array for all the encoding we have to do\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mtitles_coded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtitle_encoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray_from_pd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[0msex_coded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msex_encoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray_from_pd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mpclass_coded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPclass_encoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray_from_pd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPclass\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    609\u001b[0m                                        copy=True)\n\u001b[0;32m    610\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 611\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transform_new\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\u001b[0m in \u001b[0;36m_transform_new\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mX_int\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle_unknown\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle_unknown\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m         \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_mask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\u001b[0m in \u001b[0;36m_transform\u001b[1;34m(self, X, handle_unknown)\u001b[0m\n\u001b[0;32m    105\u001b[0m                     msg = (\"Found unknown categories {0} in column {1}\"\n\u001b[0;32m    106\u001b[0m                            \" during transform\".format(diff, i))\n\u001b[1;32m--> 107\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m                     \u001b[1;31m# Set the problematic rows to an acceptable value and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found unknown categories ['Dona.'] in column 0 during transform"
     ]
    }
   ],
   "source": [
    "arr_return_test = create_onehotencoded_features(test_data_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thought this might be an issue, and turns out it is. We have some values for categorical variables that are only seen in the test data, not in the train set, so our encoder doesn't know how to deal with those. Luckily, according to documentation (https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing-categorical-features) we can set the `handle_unknown = 'ignore` and we will ignore anything not seen in the training data. We could alternatively take all the entries from our training and test data and create the encoding from that, but I think using the `handle_unknown` better replicates a production environment, so we will do it this way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "title_encoder = OneHotEncoder(handle_unknown = 'ignore').fit(array_from_pd(train_data_new.title))\n",
    "sex_encoder = OneHotEncoder(handle_unknown = 'ignore').fit(array_from_pd(train_data_new.Sex))\n",
    "Pclass_encoder = OneHotEncoder(handle_unknown = 'ignore').fit(array_from_pd(train_data_new.Pclass))\n",
    "Cabin_encoder = OneHotEncoder(handle_unknown = 'ignore').fit(array_from_pd(train_data_new.Cabin))\n",
    "Embarked_encoder = OneHotEncoder(handle_unknown = 'ignore').fit(array_from_pd(train_data_new.Embarked))\n",
    "\n",
    "arr_return_test = create_onehotencoded_features(test_data_new)\n",
    "arr_return_train = create_onehotencoded_features(train_data_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we have done all the preprocessing that I care to do, so let's get rid of the columns we have expanded in the training and test data and tack on the one-hot-encoded features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
      "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked', 'ticket_prefix',\n",
      "       'ticket_num_digits', 'title'],\n",
      "      dtype='object')\n",
      "Index(['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch',\n",
      "       'Ticket', 'Fare', 'Cabin', 'Embarked', 'ticket_prefix',\n",
      "       'ticket_num_digits', 'title'],\n",
      "      dtype='object')\n",
      "(891, 180)\n",
      "(418, 180)\n"
     ]
    }
   ],
   "source": [
    "# find out which column we should be dropping\n",
    "print(train_data_new.columns)\n",
    "print(test_data_new.columns)\n",
    "\n",
    "# only keep the Age, SibSp, Parch, Fare, ticket_prefix, ticket_num_digits cols\n",
    "\n",
    "train_data_final = train_data_new[['Age', 'SibSp', 'Parch', 'Fare', 'ticket_prefix', 'ticket_num_digits']]\n",
    "test_data_final = test_data_new[['Age', 'SibSp', 'Parch', 'Fare', 'ticket_prefix', 'ticket_num_digits']]\n",
    "\n",
    "train_data_final_ar = np.concatenate((train_data_final.values, arr_return_train), axis = 1)\n",
    "test_data_final_ar = np.concatenate((test_data_final.values, arr_return_test), axis = 1)\n",
    "\n",
    "print(train_data_final_ar.shape)\n",
    "print(test_data_final_ar.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, finally, we can do some machine learning. We're going to try some logistic regression, decision trees, and randomForest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johnb\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-2aefa074ef0d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSurvived\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mlog_fit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_data_final_ar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1286\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1287\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=_dtype, order=\"C\",\n\u001b[1;32m-> 1288\u001b[1;33m                          accept_large_sparse=solver != 'liblinear')\n\u001b[0m\u001b[0;32m   1289\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1290\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    754\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    755\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 756\u001b[1;33m                     estimator=estimator)\n\u001b[0m\u001b[0;32m    757\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m             _assert_all_finite(array,\n\u001b[1;32m--> 573\u001b[1;33m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[0;32m    574\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan)\u001b[0m\n\u001b[0;32m     54\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[0;32m     55\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'infinity'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'NaN, infinity'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype_err\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# no need for scaling\n",
    "y_train = train_data.Survived\n",
    "\n",
    "log_fit = LogisticRegression().fit(X = train_data_final_ar, y = y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.isnan(train_data_final_ar))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turns out we have some NA's in our data, which make it really inconvenient to do further work. We need to deal with these somehow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId            0\n",
       "Survived               0\n",
       "Pclass                 0\n",
       "Name                   0\n",
       "Sex                    0\n",
       "Age                  177\n",
       "SibSp                  0\n",
       "Parch                  0\n",
       "Ticket                 0\n",
       "Fare                   0\n",
       "Cabin                687\n",
       "Embarked               2\n",
       "ticket_prefix          0\n",
       "ticket_num_digits      0\n",
       "title                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId            0\n",
       "Pclass                 0\n",
       "Name                   0\n",
       "Sex                    0\n",
       "Age                   86\n",
       "SibSp                  0\n",
       "Parch                  0\n",
       "Ticket                 0\n",
       "Fare                   1\n",
       "Cabin                327\n",
       "Embarked               0\n",
       "ticket_prefix          0\n",
       "ticket_num_digits      0\n",
       "title                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get around the issue of missing values, we will set them equal to zero because I'm getting tired of preprocessing at this point. A more robust approach might use the medians for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_final_ar = np.nan_to_num(train_data_final_ar)\n",
    "test_data_final_ar = np.nan_to_num(test_data_final_ar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression results:\n",
      "0.8574635241301908\n",
      "[[492  57]\n",
      " [ 70 272]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johnb\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "log_fit = LogisticRegression().fit(X = train_data_final_ar, y = y_train)\n",
    "\n",
    "log_preds = log_fit.predict(train_data_final_ar)\n",
    "log_accuracy = accuracy_score(y_pred=log_preds, y_true=y_train)\n",
    "print(\"Logistic Regression results:\")\n",
    "print(log_accuracy)\n",
    "print(confusion_matrix(y_pred=log_preds, y_true=y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome. We created some value over just predicting based on gender, with an accuracy of about 86%. We are doing better with both false positives and false negatives, and more or less equally so for both. With logistic regression, there aren't really too many hyperparameters to speak of, so we will leave this alone for now.\n",
    "\n",
    "One thing we forgot to do- this model is trained on our entire training set, with no sort of validation set (test set is left external and only really for kaggle use). We will do cross-validation here, because we want to maximize all the data being used for training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy\n",
      "0.8261011803427534\n",
      "stdev accuracy\n",
      "0.03420452860078454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johnb\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\johnb\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\johnb\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\johnb\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\johnb\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\johnb\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\johnb\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\johnb\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\johnb\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\johnb\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "logistic_reg = LogisticRegression()\n",
    "scores = cross_val_score(logistic_reg, train_data_final_ar, y_train, cv = 10)\n",
    "print(\"Mean accuracy\")\n",
    "print(np.mean(scores))\n",
    "print(\"stdev accuracy\")\n",
    "print(np.std(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, we we can still be relatively certain that our model is performing better than baseline, but perhaps not to the level that we had above.\n",
    "\n",
    "Let's see if a decision tree can do any better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy\n",
      "0.7901191692202929\n",
      "stdev accuracy\n",
      "0.0522247658769595\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# use default hyperparameters\n",
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "scores = cross_val_score(clf, train_data_final_ar, y_train, cv = 10)\n",
    "print(\"Mean accuracy\")\n",
    "print(np.mean(scores))\n",
    "print(\"stdev accuracy\")\n",
    "print(np.std(scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So with a decision tree, we aren't getting as good of results as a logistic regression and it's a little unclear whether these are better than our baseline of about 78%. We should note that the sklearn implementation of a decision tree goes all the way until you have one sample in each leaf node- we shouldn't really expect this to generalize well. With a little hyperparameter tuning, we can change that and see if we get any better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johnb\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\johnb\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\johnb\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\johnb\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\johnb\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\johnb\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\johnb\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split5_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\johnb\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split6_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\johnb\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split7_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\johnb\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split8_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\johnb\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split9_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\johnb\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split7_train_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split8_train_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>split9_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.005197</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.782267</td>\n",
       "      <td>0.782267</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 1}</td>\n",
       "      <td>14</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.784020</td>\n",
       "      <td>0.788889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.764045</td>\n",
       "      <td>0.784289</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.778055</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.785803</td>\n",
       "      <td>0.001834</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.033163</td>\n",
       "      <td>0.003681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.006000</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.789001</td>\n",
       "      <td>0.789002</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 2}</td>\n",
       "      <td>13</td>\n",
       "      <td>0.744444</td>\n",
       "      <td>0.794007</td>\n",
       "      <td>0.744444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.775281</td>\n",
       "      <td>0.790524</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.788030</td>\n",
       "      <td>0.795455</td>\n",
       "      <td>0.788294</td>\n",
       "      <td>0.002002</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.037831</td>\n",
       "      <td>0.004209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.007200</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.820426</td>\n",
       "      <td>0.830778</td>\n",
       "      <td>3</td>\n",
       "      <td>{'max_depth': 3}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.811111</td>\n",
       "      <td>0.838951</td>\n",
       "      <td>0.811111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.831671</td>\n",
       "      <td>0.876404</td>\n",
       "      <td>0.831671</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.821918</td>\n",
       "      <td>0.001599</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.029145</td>\n",
       "      <td>0.006590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.006400</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.809203</td>\n",
       "      <td>0.847738</td>\n",
       "      <td>4</td>\n",
       "      <td>{'max_depth': 4}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.841646</td>\n",
       "      <td>0.876404</td>\n",
       "      <td>0.845387</td>\n",
       "      <td>0.829545</td>\n",
       "      <td>0.849315</td>\n",
       "      <td>0.001959</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.044470</td>\n",
       "      <td>0.006695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.007601</td>\n",
       "      <td>0.001599</td>\n",
       "      <td>0.809203</td>\n",
       "      <td>0.866567</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 5}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.871411</td>\n",
       "      <td>0.788889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.775281</td>\n",
       "      <td>0.864090</td>\n",
       "      <td>0.898876</td>\n",
       "      <td>0.862843</td>\n",
       "      <td>0.795455</td>\n",
       "      <td>0.871731</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.001959</td>\n",
       "      <td>0.047582</td>\n",
       "      <td>0.007717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.011600</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.810325</td>\n",
       "      <td>0.950367</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 10}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.956305</td>\n",
       "      <td>0.788889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.764045</td>\n",
       "      <td>0.943890</td>\n",
       "      <td>0.865169</td>\n",
       "      <td>0.947631</td>\n",
       "      <td>0.784091</td>\n",
       "      <td>0.962640</td>\n",
       "      <td>0.002154</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.045656</td>\n",
       "      <td>0.006805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.010801</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.797980</td>\n",
       "      <td>0.987030</td>\n",
       "      <td>15</td>\n",
       "      <td>{'max_depth': 15}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.985019</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.730337</td>\n",
       "      <td>0.985037</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>0.982544</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.990037</td>\n",
       "      <td>0.003580</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050715</td>\n",
       "      <td>0.003311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.009811</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.791246</td>\n",
       "      <td>0.992518</td>\n",
       "      <td>20</td>\n",
       "      <td>{'max_depth': 20}</td>\n",
       "      <td>6</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.992509</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.741573</td>\n",
       "      <td>0.993766</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.991272</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.993773</td>\n",
       "      <td>0.003814</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.052471</td>\n",
       "      <td>0.000790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.010799</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.790123</td>\n",
       "      <td>0.992518</td>\n",
       "      <td>25</td>\n",
       "      <td>{'max_depth': 25}</td>\n",
       "      <td>7</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.992509</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.741573</td>\n",
       "      <td>0.993766</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.991272</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.993773</td>\n",
       "      <td>0.002562</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.052199</td>\n",
       "      <td>0.000790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.009813</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.790123</td>\n",
       "      <td>0.992518</td>\n",
       "      <td>30</td>\n",
       "      <td>{'max_depth': 30}</td>\n",
       "      <td>7</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.992509</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.741573</td>\n",
       "      <td>0.993766</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.991272</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.993773</td>\n",
       "      <td>0.004758</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052199</td>\n",
       "      <td>0.000790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.007607</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.790123</td>\n",
       "      <td>0.992518</td>\n",
       "      <td>40</td>\n",
       "      <td>{'max_depth': 40}</td>\n",
       "      <td>7</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.992509</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.741573</td>\n",
       "      <td>0.993766</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.991272</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.993773</td>\n",
       "      <td>0.002801</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.052199</td>\n",
       "      <td>0.000790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.010204</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.790123</td>\n",
       "      <td>0.992518</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 50}</td>\n",
       "      <td>7</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.992509</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.741573</td>\n",
       "      <td>0.993766</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.991272</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.993773</td>\n",
       "      <td>0.002589</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.052199</td>\n",
       "      <td>0.000790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.009813</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.790123</td>\n",
       "      <td>0.992518</td>\n",
       "      <td>75</td>\n",
       "      <td>{'max_depth': 75}</td>\n",
       "      <td>7</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.992509</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.741573</td>\n",
       "      <td>0.993766</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.991272</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.993773</td>\n",
       "      <td>0.005807</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052199</td>\n",
       "      <td>0.000790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.009606</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.790123</td>\n",
       "      <td>0.992518</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 100}</td>\n",
       "      <td>7</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.992509</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.741573</td>\n",
       "      <td>0.993766</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.991272</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.993773</td>\n",
       "      <td>0.003188</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.052199</td>\n",
       "      <td>0.000790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14 rows  31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0        0.005197         0.000400         0.782267          0.782267   \n",
       "1        0.006000         0.000400         0.789001          0.789002   \n",
       "2        0.007200         0.000800         0.820426          0.830778   \n",
       "3        0.006400         0.000800         0.809203          0.847738   \n",
       "4        0.007601         0.001599         0.809203          0.866567   \n",
       "5        0.011600         0.000400         0.810325          0.950367   \n",
       "6        0.010801         0.000000         0.797980          0.987030   \n",
       "7        0.009811         0.000800         0.791246          0.992518   \n",
       "8        0.010799         0.000800         0.790123          0.992518   \n",
       "9        0.009813         0.000000         0.790123          0.992518   \n",
       "10       0.007607         0.000800         0.790123          0.992518   \n",
       "11       0.010204         0.000400         0.790123          0.992518   \n",
       "12       0.009813         0.000000         0.790123          0.992518   \n",
       "13       0.009606         0.000800         0.790123          0.992518   \n",
       "\n",
       "   param_max_depth              params  rank_test_score  split0_test_score  \\\n",
       "0                1    {'max_depth': 1}               14           0.766667   \n",
       "1                2    {'max_depth': 2}               13           0.744444   \n",
       "2                3    {'max_depth': 3}                1           0.811111   \n",
       "3                4    {'max_depth': 4}                3           0.800000   \n",
       "4                5    {'max_depth': 5}                3           0.755556   \n",
       "5               10   {'max_depth': 10}                2           0.766667   \n",
       "6               15   {'max_depth': 15}                5           0.755556   \n",
       "7               20   {'max_depth': 20}                6           0.766667   \n",
       "8               25   {'max_depth': 25}                7           0.766667   \n",
       "9               30   {'max_depth': 30}                7           0.766667   \n",
       "10              40   {'max_depth': 40}                7           0.766667   \n",
       "11              50   {'max_depth': 50}                7           0.766667   \n",
       "12              75   {'max_depth': 75}                7           0.766667   \n",
       "13             100  {'max_depth': 100}                7           0.766667   \n",
       "\n",
       "    split0_train_score  split1_test_score       ...         split7_test_score  \\\n",
       "0             0.784020           0.788889       ...                  0.764045   \n",
       "1             0.794007           0.744444       ...                  0.775281   \n",
       "2             0.838951           0.811111       ...                  0.808989   \n",
       "3             0.853933           0.755556       ...                  0.797753   \n",
       "4             0.871411           0.788889       ...                  0.775281   \n",
       "5             0.956305           0.788889       ...                  0.764045   \n",
       "6             0.985019           0.822222       ...                  0.730337   \n",
       "7             0.992509           0.800000       ...                  0.741573   \n",
       "8             0.992509           0.800000       ...                  0.741573   \n",
       "9             0.992509           0.800000       ...                  0.741573   \n",
       "10            0.992509           0.800000       ...                  0.741573   \n",
       "11            0.992509           0.800000       ...                  0.741573   \n",
       "12            0.992509           0.800000       ...                  0.741573   \n",
       "13            0.992509           0.800000       ...                  0.741573   \n",
       "\n",
       "    split7_train_score  split8_test_score  split8_train_score  \\\n",
       "0             0.784289           0.820225            0.778055   \n",
       "1             0.790524           0.797753            0.788030   \n",
       "2             0.831671           0.876404            0.831671   \n",
       "3             0.841646           0.876404            0.845387   \n",
       "4             0.864090           0.898876            0.862843   \n",
       "5             0.943890           0.865169            0.947631   \n",
       "6             0.985037           0.853933            0.982544   \n",
       "7             0.993766           0.831461            0.991272   \n",
       "8             0.993766           0.831461            0.991272   \n",
       "9             0.993766           0.831461            0.991272   \n",
       "10            0.993766           0.831461            0.991272   \n",
       "11            0.993766           0.831461            0.991272   \n",
       "12            0.993766           0.831461            0.991272   \n",
       "13            0.993766           0.831461            0.991272   \n",
       "\n",
       "    split9_test_score  split9_train_score  std_fit_time  std_score_time  \\\n",
       "0            0.750000            0.785803      0.001834        0.001200   \n",
       "1            0.795455            0.788294      0.002002        0.001200   \n",
       "2            0.818182            0.821918      0.001599        0.001600   \n",
       "3            0.829545            0.849315      0.001959        0.001600   \n",
       "4            0.795455            0.871731      0.001200        0.001959   \n",
       "5            0.784091            0.962640      0.002154        0.001200   \n",
       "6            0.772727            0.990037      0.003580        0.000000   \n",
       "7            0.772727            0.993773      0.003814        0.001600   \n",
       "8            0.772727            0.993773      0.002562        0.001600   \n",
       "9            0.772727            0.993773      0.004758        0.000000   \n",
       "10           0.772727            0.993773      0.002801        0.001600   \n",
       "11           0.772727            0.993773      0.002589        0.001200   \n",
       "12           0.772727            0.993773      0.005807        0.000000   \n",
       "13           0.772727            0.993773      0.003188        0.001600   \n",
       "\n",
       "    std_test_score  std_train_score  \n",
       "0         0.033163         0.003681  \n",
       "1         0.037831         0.004209  \n",
       "2         0.029145         0.006590  \n",
       "3         0.044470         0.006695  \n",
       "4         0.047582         0.007717  \n",
       "5         0.045656         0.006805  \n",
       "6         0.050715         0.003311  \n",
       "7         0.052471         0.000790  \n",
       "8         0.052199         0.000790  \n",
       "9         0.052199         0.000790  \n",
       "10        0.052199         0.000790  \n",
       "11        0.052199         0.000790  \n",
       "12        0.052199         0.000790  \n",
       "13        0.052199         0.000790  \n",
       "\n",
       "[14 rows x 31 columns]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "depths = {'max_depth' : [1, 2, 3, 4, 5, 10, 15, 20, 25, 30, 40, 50, 75, 100]}\n",
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "cv_fit = GridSearchCV(clf, depths, scoring = 'accuracy', cv = 10, n_jobs = -1)\n",
    "results = cv_fit.fit(train_data_final_ar, y_train)\n",
    "pd.DataFrame(results.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright so with a maximum depth of 3 on our decision tree, we can see that we have a mean test score of about 82%, which is an improvement over the baseline, but not over the logistic regression.\n",
    "\n",
    "While we could do some visualization and more interpretation here, I'm just going to go straight onto random forests. We will go straight into hyperparameter tuning. The `n_estimators` is how many trees we generate, `min_samples_leaf` is a way that we can control tree depth by specifying the minimum number of samples per leaf, and `max_features` specifies how many variables we test at each node. The idea here is that we want a lot of trees that come to the same decisions independently, and these hyperparameters will ensure that our trees are pretty different.\n",
    "\n",
    "We should also note that this should be decently computationally expensive..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 224.49790501594543 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johnb\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\johnb\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\johnb\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\johnb\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\johnb\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\johnb\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\johnb\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split5_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\johnb\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split6_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\johnb\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split7_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\johnb\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split8_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\johnb\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split9_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\johnb\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split7_train_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split8_train_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>split9_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>1.105567</td>\n",
       "      <td>0.065243</td>\n",
       "      <td>0.839506</td>\n",
       "      <td>0.870684</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_features': 50, 'min_samples_leaf': 5, 'n...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.811111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.870324</td>\n",
       "      <td>0.876404</td>\n",
       "      <td>0.866584</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.864259</td>\n",
       "      <td>0.270026</td>\n",
       "      <td>0.045878</td>\n",
       "      <td>0.044160</td>\n",
       "      <td>0.006539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>1.118000</td>\n",
       "      <td>0.026000</td>\n",
       "      <td>0.838384</td>\n",
       "      <td>0.870558</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>250</td>\n",
       "      <td>{'max_features': 50, 'min_samples_leaf': 5, 'n...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.870324</td>\n",
       "      <td>0.865169</td>\n",
       "      <td>0.866584</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.869240</td>\n",
       "      <td>0.301087</td>\n",
       "      <td>0.004472</td>\n",
       "      <td>0.042516</td>\n",
       "      <td>0.005798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0.319600</td>\n",
       "      <td>0.018400</td>\n",
       "      <td>0.838384</td>\n",
       "      <td>0.871181</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_features': 50, 'min_samples_leaf': 5, 'n...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.872818</td>\n",
       "      <td>0.876404</td>\n",
       "      <td>0.869077</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.869240</td>\n",
       "      <td>0.012706</td>\n",
       "      <td>0.008617</td>\n",
       "      <td>0.045199</td>\n",
       "      <td>0.006028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>1.775158</td>\n",
       "      <td>0.073948</td>\n",
       "      <td>0.836139</td>\n",
       "      <td>0.869936</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_features': 50, 'min_samples_leaf': 5, 'n...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.811111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.867830</td>\n",
       "      <td>0.865169</td>\n",
       "      <td>0.864090</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.865504</td>\n",
       "      <td>0.042311</td>\n",
       "      <td>0.042141</td>\n",
       "      <td>0.043643</td>\n",
       "      <td>0.006023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0.134001</td>\n",
       "      <td>0.007999</td>\n",
       "      <td>0.836139</td>\n",
       "      <td>0.868937</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_features': 50, 'min_samples_leaf': 5, 'n...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.788889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.871571</td>\n",
       "      <td>0.876404</td>\n",
       "      <td>0.866584</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.865504</td>\n",
       "      <td>0.037535</td>\n",
       "      <td>0.005933</td>\n",
       "      <td>0.044947</td>\n",
       "      <td>0.005245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>0.585534</td>\n",
       "      <td>0.031180</td>\n",
       "      <td>0.836139</td>\n",
       "      <td>0.874549</td>\n",
       "      <td>100</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 100, 'min_samples_leaf': 7, '...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.871571</td>\n",
       "      <td>0.876404</td>\n",
       "      <td>0.865337</td>\n",
       "      <td>0.829545</td>\n",
       "      <td>0.872976</td>\n",
       "      <td>0.235594</td>\n",
       "      <td>0.017446</td>\n",
       "      <td>0.050083</td>\n",
       "      <td>0.005910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>1.748309</td>\n",
       "      <td>0.083600</td>\n",
       "      <td>0.836139</td>\n",
       "      <td>0.869686</td>\n",
       "      <td>75</td>\n",
       "      <td>7</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_features': 75, 'min_samples_leaf': 7, 'n...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.811111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.871571</td>\n",
       "      <td>0.865169</td>\n",
       "      <td>0.865337</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.865504</td>\n",
       "      <td>0.133755</td>\n",
       "      <td>0.069384</td>\n",
       "      <td>0.047516</td>\n",
       "      <td>0.005668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0.608399</td>\n",
       "      <td>0.028401</td>\n",
       "      <td>0.835017</td>\n",
       "      <td>0.867690</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 50, 'min_samples_leaf': 5, 'n...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.869077</td>\n",
       "      <td>0.876404</td>\n",
       "      <td>0.860349</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.866750</td>\n",
       "      <td>0.190793</td>\n",
       "      <td>0.018195</td>\n",
       "      <td>0.043451</td>\n",
       "      <td>0.007560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>1.186821</td>\n",
       "      <td>0.065290</td>\n",
       "      <td>0.835017</td>\n",
       "      <td>0.893379</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_features': 50, 'min_samples_leaf': 3, 'n...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.892768</td>\n",
       "      <td>0.876404</td>\n",
       "      <td>0.887781</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.890411</td>\n",
       "      <td>0.291438</td>\n",
       "      <td>0.044983</td>\n",
       "      <td>0.049566</td>\n",
       "      <td>0.004447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>0.154419</td>\n",
       "      <td>0.005432</td>\n",
       "      <td>0.835017</td>\n",
       "      <td>0.872929</td>\n",
       "      <td>100</td>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_features': 100, 'min_samples_leaf': 7, '...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.788889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.871571</td>\n",
       "      <td>0.876404</td>\n",
       "      <td>0.869077</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.874222</td>\n",
       "      <td>0.060014</td>\n",
       "      <td>0.004504</td>\n",
       "      <td>0.045657</td>\n",
       "      <td>0.006688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.407301</td>\n",
       "      <td>0.019127</td>\n",
       "      <td>0.833895</td>\n",
       "      <td>0.859210</td>\n",
       "      <td>50</td>\n",
       "      <td>7</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_features': 50, 'min_samples_leaf': 7, 'n...</td>\n",
       "      <td>11</td>\n",
       "      <td>0.811111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.775281</td>\n",
       "      <td>0.860349</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>0.852868</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.855542</td>\n",
       "      <td>0.167952</td>\n",
       "      <td>0.011285</td>\n",
       "      <td>0.044075</td>\n",
       "      <td>0.006521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>0.469792</td>\n",
       "      <td>0.019963</td>\n",
       "      <td>0.833895</td>\n",
       "      <td>0.874424</td>\n",
       "      <td>100</td>\n",
       "      <td>7</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_features': 100, 'min_samples_leaf': 7, '...</td>\n",
       "      <td>11</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.871571</td>\n",
       "      <td>0.865169</td>\n",
       "      <td>0.864090</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.871731</td>\n",
       "      <td>0.143200</td>\n",
       "      <td>0.014938</td>\n",
       "      <td>0.047049</td>\n",
       "      <td>0.006269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>0.421528</td>\n",
       "      <td>0.010070</td>\n",
       "      <td>0.833895</td>\n",
       "      <td>0.869437</td>\n",
       "      <td>75</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 75, 'min_samples_leaf': 7, 'n...</td>\n",
       "      <td>11</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.870324</td>\n",
       "      <td>0.876404</td>\n",
       "      <td>0.865337</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.861768</td>\n",
       "      <td>0.187481</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.047854</td>\n",
       "      <td>0.005705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>1.325356</td>\n",
       "      <td>0.059069</td>\n",
       "      <td>0.833895</td>\n",
       "      <td>0.874424</td>\n",
       "      <td>100</td>\n",
       "      <td>7</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_features': 100, 'min_samples_leaf': 7, '...</td>\n",
       "      <td>11</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.871571</td>\n",
       "      <td>0.865169</td>\n",
       "      <td>0.866584</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.872976</td>\n",
       "      <td>0.248836</td>\n",
       "      <td>0.043731</td>\n",
       "      <td>0.047891</td>\n",
       "      <td>0.005800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>2.382435</td>\n",
       "      <td>0.080873</td>\n",
       "      <td>0.833895</td>\n",
       "      <td>0.874674</td>\n",
       "      <td>100</td>\n",
       "      <td>7</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_features': 100, 'min_samples_leaf': 7, '...</td>\n",
       "      <td>11</td>\n",
       "      <td>0.811111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.775281</td>\n",
       "      <td>0.874065</td>\n",
       "      <td>0.876404</td>\n",
       "      <td>0.866584</td>\n",
       "      <td>0.840909</td>\n",
       "      <td>0.870486</td>\n",
       "      <td>0.306166</td>\n",
       "      <td>0.063634</td>\n",
       "      <td>0.048720</td>\n",
       "      <td>0.005610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>1.687189</td>\n",
       "      <td>0.137257</td>\n",
       "      <td>0.833895</td>\n",
       "      <td>0.859459</td>\n",
       "      <td>50</td>\n",
       "      <td>7</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_features': 50, 'min_samples_leaf': 7, 'n...</td>\n",
       "      <td>11</td>\n",
       "      <td>0.811111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.775281</td>\n",
       "      <td>0.859102</td>\n",
       "      <td>0.876404</td>\n",
       "      <td>0.852868</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.860523</td>\n",
       "      <td>0.061936</td>\n",
       "      <td>0.072854</td>\n",
       "      <td>0.045438</td>\n",
       "      <td>0.005265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>0.583927</td>\n",
       "      <td>0.032581</td>\n",
       "      <td>0.832772</td>\n",
       "      <td>0.869062</td>\n",
       "      <td>75</td>\n",
       "      <td>7</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_features': 75, 'min_samples_leaf': 7, 'n...</td>\n",
       "      <td>17</td>\n",
       "      <td>0.811111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.871571</td>\n",
       "      <td>0.865169</td>\n",
       "      <td>0.860349</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.861768</td>\n",
       "      <td>0.311181</td>\n",
       "      <td>0.022358</td>\n",
       "      <td>0.044057</td>\n",
       "      <td>0.006898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>1.101200</td>\n",
       "      <td>0.039600</td>\n",
       "      <td>0.832772</td>\n",
       "      <td>0.909217</td>\n",
       "      <td>75</td>\n",
       "      <td>3</td>\n",
       "      <td>250</td>\n",
       "      <td>{'max_features': 75, 'min_samples_leaf': 3, 'n...</td>\n",
       "      <td>17</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.764045</td>\n",
       "      <td>0.915212</td>\n",
       "      <td>0.865169</td>\n",
       "      <td>0.900249</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.900374</td>\n",
       "      <td>0.284998</td>\n",
       "      <td>0.031264</td>\n",
       "      <td>0.053584</td>\n",
       "      <td>0.006718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>0.535065</td>\n",
       "      <td>0.027220</td>\n",
       "      <td>0.832772</td>\n",
       "      <td>0.914329</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 100, 'min_samples_leaf': 3, '...</td>\n",
       "      <td>17</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.775281</td>\n",
       "      <td>0.915212</td>\n",
       "      <td>0.876404</td>\n",
       "      <td>0.908978</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.911582</td>\n",
       "      <td>0.300366</td>\n",
       "      <td>0.016299</td>\n",
       "      <td>0.055300</td>\n",
       "      <td>0.003243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>0.662102</td>\n",
       "      <td>0.031397</td>\n",
       "      <td>0.832772</td>\n",
       "      <td>0.888640</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 100, 'min_samples_leaf': 5, '...</td>\n",
       "      <td>17</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.887781</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>0.879052</td>\n",
       "      <td>0.840909</td>\n",
       "      <td>0.887920</td>\n",
       "      <td>0.158000</td>\n",
       "      <td>0.017764</td>\n",
       "      <td>0.043712</td>\n",
       "      <td>0.004622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>1.873608</td>\n",
       "      <td>0.051599</td>\n",
       "      <td>0.832772</td>\n",
       "      <td>0.894376</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_features': 50, 'min_samples_leaf': 3, 'n...</td>\n",
       "      <td>17</td>\n",
       "      <td>0.811111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.892768</td>\n",
       "      <td>0.865169</td>\n",
       "      <td>0.890274</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.892902</td>\n",
       "      <td>0.018006</td>\n",
       "      <td>0.012321</td>\n",
       "      <td>0.048681</td>\n",
       "      <td>0.003149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>1.340607</td>\n",
       "      <td>0.041423</td>\n",
       "      <td>0.832772</td>\n",
       "      <td>0.908967</td>\n",
       "      <td>75</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_features': 75, 'min_samples_leaf': 3, 'n...</td>\n",
       "      <td>17</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.764045</td>\n",
       "      <td>0.917706</td>\n",
       "      <td>0.865169</td>\n",
       "      <td>0.902743</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.900374</td>\n",
       "      <td>0.303963</td>\n",
       "      <td>0.029146</td>\n",
       "      <td>0.052634</td>\n",
       "      <td>0.006519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>0.892484</td>\n",
       "      <td>0.025360</td>\n",
       "      <td>0.831650</td>\n",
       "      <td>0.867815</td>\n",
       "      <td>75</td>\n",
       "      <td>7</td>\n",
       "      <td>250</td>\n",
       "      <td>{'max_features': 75, 'min_samples_leaf': 7, 'n...</td>\n",
       "      <td>23</td>\n",
       "      <td>0.811111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.870324</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>0.862843</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.860523</td>\n",
       "      <td>0.306271</td>\n",
       "      <td>0.003939</td>\n",
       "      <td>0.045225</td>\n",
       "      <td>0.006962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0.530183</td>\n",
       "      <td>0.034035</td>\n",
       "      <td>0.831650</td>\n",
       "      <td>0.857590</td>\n",
       "      <td>50</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 50, 'min_samples_leaf': 7, 'n...</td>\n",
       "      <td>23</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.775281</td>\n",
       "      <td>0.857855</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>0.849127</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.850560</td>\n",
       "      <td>0.158624</td>\n",
       "      <td>0.017311</td>\n",
       "      <td>0.042140</td>\n",
       "      <td>0.007204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>1.050565</td>\n",
       "      <td>0.048719</td>\n",
       "      <td>0.831650</td>\n",
       "      <td>0.858087</td>\n",
       "      <td>50</td>\n",
       "      <td>7</td>\n",
       "      <td>250</td>\n",
       "      <td>{'max_features': 50, 'min_samples_leaf': 7, 'n...</td>\n",
       "      <td>23</td>\n",
       "      <td>0.811111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.775281</td>\n",
       "      <td>0.857855</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>0.850374</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.860523</td>\n",
       "      <td>0.287935</td>\n",
       "      <td>0.036467</td>\n",
       "      <td>0.042393</td>\n",
       "      <td>0.006595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>0.660799</td>\n",
       "      <td>0.015600</td>\n",
       "      <td>0.831650</td>\n",
       "      <td>0.881906</td>\n",
       "      <td>75</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_features': 75, 'min_samples_leaf': 5, 'n...</td>\n",
       "      <td>23</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.882793</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>0.880299</td>\n",
       "      <td>0.840909</td>\n",
       "      <td>0.871731</td>\n",
       "      <td>0.291264</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.048656</td>\n",
       "      <td>0.005209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>1.165100</td>\n",
       "      <td>0.066984</td>\n",
       "      <td>0.831650</td>\n",
       "      <td>0.869935</td>\n",
       "      <td>75</td>\n",
       "      <td>7</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_features': 75, 'min_samples_leaf': 7, 'n...</td>\n",
       "      <td>23</td>\n",
       "      <td>0.811111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.870324</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>0.865337</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.865504</td>\n",
       "      <td>0.288183</td>\n",
       "      <td>0.047238</td>\n",
       "      <td>0.044463</td>\n",
       "      <td>0.006581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>1.289052</td>\n",
       "      <td>0.040023</td>\n",
       "      <td>0.831650</td>\n",
       "      <td>0.874549</td>\n",
       "      <td>100</td>\n",
       "      <td>7</td>\n",
       "      <td>250</td>\n",
       "      <td>{'max_features': 100, 'min_samples_leaf': 7, '...</td>\n",
       "      <td>23</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.872818</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>0.866584</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.874222</td>\n",
       "      <td>0.211892</td>\n",
       "      <td>0.030911</td>\n",
       "      <td>0.047378</td>\n",
       "      <td>0.005306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0.742964</td>\n",
       "      <td>0.014133</td>\n",
       "      <td>0.830527</td>\n",
       "      <td>0.919191</td>\n",
       "      <td>125</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 125, 'min_samples_leaf': 3, '...</td>\n",
       "      <td>29</td>\n",
       "      <td>0.788889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.764045</td>\n",
       "      <td>0.923940</td>\n",
       "      <td>0.876404</td>\n",
       "      <td>0.921446</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.919054</td>\n",
       "      <td>0.353836</td>\n",
       "      <td>0.011559</td>\n",
       "      <td>0.050785</td>\n",
       "      <td>0.004403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>2.049325</td>\n",
       "      <td>0.065678</td>\n",
       "      <td>0.830527</td>\n",
       "      <td>0.885024</td>\n",
       "      <td>75</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_features': 75, 'min_samples_leaf': 5, 'n...</td>\n",
       "      <td>29</td>\n",
       "      <td>0.811111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.775281</td>\n",
       "      <td>0.881546</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>0.879052</td>\n",
       "      <td>0.840909</td>\n",
       "      <td>0.879203</td>\n",
       "      <td>0.103773</td>\n",
       "      <td>0.049282</td>\n",
       "      <td>0.049713</td>\n",
       "      <td>0.004743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.141201</td>\n",
       "      <td>0.018400</td>\n",
       "      <td>0.803591</td>\n",
       "      <td>0.810326</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 10, 'min_samples_leaf': 5, 'n...</td>\n",
       "      <td>162</td>\n",
       "      <td>0.811111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.807980</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.812968</td>\n",
       "      <td>0.795455</td>\n",
       "      <td>0.809465</td>\n",
       "      <td>0.027426</td>\n",
       "      <td>0.014334</td>\n",
       "      <td>0.030029</td>\n",
       "      <td>0.007127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.590799</td>\n",
       "      <td>0.042400</td>\n",
       "      <td>0.802469</td>\n",
       "      <td>0.812198</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_features': 10, 'min_samples_leaf': 5, 'n...</td>\n",
       "      <td>164</td>\n",
       "      <td>0.811111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.810474</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.809227</td>\n",
       "      <td>0.795455</td>\n",
       "      <td>0.810710</td>\n",
       "      <td>0.131735</td>\n",
       "      <td>0.024606</td>\n",
       "      <td>0.034328</td>\n",
       "      <td>0.005848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.693602</td>\n",
       "      <td>0.070400</td>\n",
       "      <td>0.800224</td>\n",
       "      <td>0.815938</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_features': 10, 'min_samples_leaf': 5, 'n...</td>\n",
       "      <td>165</td>\n",
       "      <td>0.788889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.822943</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.816708</td>\n",
       "      <td>0.795455</td>\n",
       "      <td>0.810710</td>\n",
       "      <td>0.298761</td>\n",
       "      <td>0.043531</td>\n",
       "      <td>0.034871</td>\n",
       "      <td>0.004106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.928000</td>\n",
       "      <td>0.087600</td>\n",
       "      <td>0.800224</td>\n",
       "      <td>0.818931</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_features': 10, 'min_samples_leaf': 5, 'n...</td>\n",
       "      <td>165</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>...</td>\n",
       "      <td>0.764045</td>\n",
       "      <td>0.819202</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.819202</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.816936</td>\n",
       "      <td>0.257669</td>\n",
       "      <td>0.080587</td>\n",
       "      <td>0.035283</td>\n",
       "      <td>0.003805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.277998</td>\n",
       "      <td>0.012800</td>\n",
       "      <td>0.799102</td>\n",
       "      <td>0.800102</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 10, 'min_samples_leaf': 7, 'n...</td>\n",
       "      <td>167</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.810474</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.794264</td>\n",
       "      <td>0.806818</td>\n",
       "      <td>0.808219</td>\n",
       "      <td>0.156217</td>\n",
       "      <td>0.010553</td>\n",
       "      <td>0.027231</td>\n",
       "      <td>0.012033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.062178</td>\n",
       "      <td>0.005205</td>\n",
       "      <td>0.799102</td>\n",
       "      <td>0.806210</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_features': 10, 'min_samples_leaf': 5, 'n...</td>\n",
       "      <td>167</td>\n",
       "      <td>0.788889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.815461</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.819202</td>\n",
       "      <td>0.806818</td>\n",
       "      <td>0.810710</td>\n",
       "      <td>0.003166</td>\n",
       "      <td>0.002566</td>\n",
       "      <td>0.036606</td>\n",
       "      <td>0.017280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.298800</td>\n",
       "      <td>0.023200</td>\n",
       "      <td>0.797980</td>\n",
       "      <td>0.814066</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>250</td>\n",
       "      <td>{'max_features': 10, 'min_samples_leaf': 5, 'n...</td>\n",
       "      <td>169</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>...</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.824190</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.814214</td>\n",
       "      <td>0.795455</td>\n",
       "      <td>0.813200</td>\n",
       "      <td>0.016203</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.034880</td>\n",
       "      <td>0.005623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.185649</td>\n",
       "      <td>0.014836</td>\n",
       "      <td>0.796857</td>\n",
       "      <td>0.801221</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_features': 10, 'min_samples_leaf': 7, 'n...</td>\n",
       "      <td>170</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.807980</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.785536</td>\n",
       "      <td>0.806818</td>\n",
       "      <td>0.811955</td>\n",
       "      <td>0.009454</td>\n",
       "      <td>0.008060</td>\n",
       "      <td>0.034265</td>\n",
       "      <td>0.008753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1.032684</td>\n",
       "      <td>0.106266</td>\n",
       "      <td>0.795735</td>\n",
       "      <td>0.816062</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_features': 10, 'min_samples_leaf': 7, 'n...</td>\n",
       "      <td>171</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.764045</td>\n",
       "      <td>0.827930</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.816708</td>\n",
       "      <td>0.806818</td>\n",
       "      <td>0.814446</td>\n",
       "      <td>0.275755</td>\n",
       "      <td>0.078957</td>\n",
       "      <td>0.035922</td>\n",
       "      <td>0.006178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.667662</td>\n",
       "      <td>0.027981</td>\n",
       "      <td>0.794613</td>\n",
       "      <td>0.802219</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_features': 10, 'min_samples_leaf': 7, 'n...</td>\n",
       "      <td>172</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.811721</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.789277</td>\n",
       "      <td>0.806818</td>\n",
       "      <td>0.809465</td>\n",
       "      <td>0.280672</td>\n",
       "      <td>0.003174</td>\n",
       "      <td>0.038882</td>\n",
       "      <td>0.007757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.504746</td>\n",
       "      <td>0.055248</td>\n",
       "      <td>0.793490</td>\n",
       "      <td>0.803216</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>250</td>\n",
       "      <td>{'max_features': 10, 'min_samples_leaf': 7, 'n...</td>\n",
       "      <td>173</td>\n",
       "      <td>0.744444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.810474</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.788030</td>\n",
       "      <td>0.795455</td>\n",
       "      <td>0.809465</td>\n",
       "      <td>0.285632</td>\n",
       "      <td>0.039668</td>\n",
       "      <td>0.038268</td>\n",
       "      <td>0.007504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.192001</td>\n",
       "      <td>0.018800</td>\n",
       "      <td>0.783389</td>\n",
       "      <td>0.790122</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_features': 10, 'min_samples_leaf': 7, 'n...</td>\n",
       "      <td>174</td>\n",
       "      <td>0.788889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.812968</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.807980</td>\n",
       "      <td>0.795455</td>\n",
       "      <td>0.810710</td>\n",
       "      <td>0.115738</td>\n",
       "      <td>0.012400</td>\n",
       "      <td>0.033396</td>\n",
       "      <td>0.021807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.059206</td>\n",
       "      <td>0.003821</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.635629</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_features': 5, 'min_samples_leaf': 3, 'n_...</td>\n",
       "      <td>175</td>\n",
       "      <td>0.644444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.617978</td>\n",
       "      <td>0.615960</td>\n",
       "      <td>0.617978</td>\n",
       "      <td>0.615960</td>\n",
       "      <td>0.613636</td>\n",
       "      <td>0.616438</td>\n",
       "      <td>0.005433</td>\n",
       "      <td>0.004355</td>\n",
       "      <td>0.018066</td>\n",
       "      <td>0.029129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.057749</td>\n",
       "      <td>0.007008</td>\n",
       "      <td>0.618406</td>\n",
       "      <td>0.622274</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_features': 5, 'min_samples_leaf': 5, 'n_...</td>\n",
       "      <td>176</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.617978</td>\n",
       "      <td>0.615960</td>\n",
       "      <td>0.617978</td>\n",
       "      <td>0.615960</td>\n",
       "      <td>0.613636</td>\n",
       "      <td>0.616438</td>\n",
       "      <td>0.002375</td>\n",
       "      <td>0.002059</td>\n",
       "      <td>0.007851</td>\n",
       "      <td>0.012466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.128198</td>\n",
       "      <td>0.017820</td>\n",
       "      <td>0.618406</td>\n",
       "      <td>0.621774</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_features': 5, 'min_samples_leaf': 7, 'n_...</td>\n",
       "      <td>176</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.617978</td>\n",
       "      <td>0.615960</td>\n",
       "      <td>0.617978</td>\n",
       "      <td>0.615960</td>\n",
       "      <td>0.613636</td>\n",
       "      <td>0.616438</td>\n",
       "      <td>0.072540</td>\n",
       "      <td>0.012709</td>\n",
       "      <td>0.007851</td>\n",
       "      <td>0.012803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.842400</td>\n",
       "      <td>0.044912</td>\n",
       "      <td>0.618406</td>\n",
       "      <td>0.619404</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_features': 5, 'min_samples_leaf': 3, 'n_...</td>\n",
       "      <td>176</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.617978</td>\n",
       "      <td>0.615960</td>\n",
       "      <td>0.617978</td>\n",
       "      <td>0.615960</td>\n",
       "      <td>0.613636</td>\n",
       "      <td>0.616438</td>\n",
       "      <td>0.323730</td>\n",
       "      <td>0.003924</td>\n",
       "      <td>0.007851</td>\n",
       "      <td>0.005592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.520275</td>\n",
       "      <td>0.036718</td>\n",
       "      <td>0.617284</td>\n",
       "      <td>0.616411</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>250</td>\n",
       "      <td>{'max_features': 5, 'min_samples_leaf': 3, 'n_...</td>\n",
       "      <td>179</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.617978</td>\n",
       "      <td>0.615960</td>\n",
       "      <td>0.617978</td>\n",
       "      <td>0.615960</td>\n",
       "      <td>0.613636</td>\n",
       "      <td>0.616438</td>\n",
       "      <td>0.281288</td>\n",
       "      <td>0.029907</td>\n",
       "      <td>0.004849</td>\n",
       "      <td>0.000499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.596383</td>\n",
       "      <td>0.047200</td>\n",
       "      <td>0.617284</td>\n",
       "      <td>0.617410</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_features': 5, 'min_samples_leaf': 3, 'n_...</td>\n",
       "      <td>179</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.617978</td>\n",
       "      <td>0.615960</td>\n",
       "      <td>0.617978</td>\n",
       "      <td>0.615960</td>\n",
       "      <td>0.613636</td>\n",
       "      <td>0.616438</td>\n",
       "      <td>0.341295</td>\n",
       "      <td>0.038441</td>\n",
       "      <td>0.004849</td>\n",
       "      <td>0.002793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.108758</td>\n",
       "      <td>0.009865</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.616286</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 5, 'min_samples_leaf': 3, 'n_...</td>\n",
       "      <td>181</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.617978</td>\n",
       "      <td>0.615960</td>\n",
       "      <td>0.617978</td>\n",
       "      <td>0.615960</td>\n",
       "      <td>0.613636</td>\n",
       "      <td>0.616438</td>\n",
       "      <td>0.004007</td>\n",
       "      <td>0.000613</td>\n",
       "      <td>0.002844</td>\n",
       "      <td>0.000436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.197348</td>\n",
       "      <td>0.023447</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_features': 5, 'min_samples_leaf': 3, 'n_...</td>\n",
       "      <td>181</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.617978</td>\n",
       "      <td>0.615960</td>\n",
       "      <td>0.617978</td>\n",
       "      <td>0.615960</td>\n",
       "      <td>0.613636</td>\n",
       "      <td>0.616438</td>\n",
       "      <td>0.097633</td>\n",
       "      <td>0.019453</td>\n",
       "      <td>0.002844</td>\n",
       "      <td>0.000317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.405174</td>\n",
       "      <td>0.045262</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 5, 'min_samples_leaf': 5, 'n_...</td>\n",
       "      <td>181</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.617978</td>\n",
       "      <td>0.615960</td>\n",
       "      <td>0.617978</td>\n",
       "      <td>0.615960</td>\n",
       "      <td>0.613636</td>\n",
       "      <td>0.616438</td>\n",
       "      <td>0.087687</td>\n",
       "      <td>0.006698</td>\n",
       "      <td>0.002844</td>\n",
       "      <td>0.000317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.267010</td>\n",
       "      <td>0.024148</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>250</td>\n",
       "      <td>{'max_features': 5, 'min_samples_leaf': 5, 'n_...</td>\n",
       "      <td>181</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.617978</td>\n",
       "      <td>0.615960</td>\n",
       "      <td>0.617978</td>\n",
       "      <td>0.615960</td>\n",
       "      <td>0.613636</td>\n",
       "      <td>0.616438</td>\n",
       "      <td>0.007072</td>\n",
       "      <td>0.005833</td>\n",
       "      <td>0.002844</td>\n",
       "      <td>0.000317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.702095</td>\n",
       "      <td>0.081219</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_features': 5, 'min_samples_leaf': 5, 'n_...</td>\n",
       "      <td>181</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.617978</td>\n",
       "      <td>0.615960</td>\n",
       "      <td>0.617978</td>\n",
       "      <td>0.615960</td>\n",
       "      <td>0.613636</td>\n",
       "      <td>0.616438</td>\n",
       "      <td>0.276842</td>\n",
       "      <td>0.045281</td>\n",
       "      <td>0.002844</td>\n",
       "      <td>0.000317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.775219</td>\n",
       "      <td>0.051586</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.616785</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_features': 5, 'min_samples_leaf': 5, 'n_...</td>\n",
       "      <td>181</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.617978</td>\n",
       "      <td>0.615960</td>\n",
       "      <td>0.617978</td>\n",
       "      <td>0.615960</td>\n",
       "      <td>0.613636</td>\n",
       "      <td>0.616438</td>\n",
       "      <td>0.297468</td>\n",
       "      <td>0.013616</td>\n",
       "      <td>0.002844</td>\n",
       "      <td>0.001830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.338970</td>\n",
       "      <td>0.028543</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 5, 'min_samples_leaf': 7, 'n_...</td>\n",
       "      <td>181</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.617978</td>\n",
       "      <td>0.615960</td>\n",
       "      <td>0.617978</td>\n",
       "      <td>0.615960</td>\n",
       "      <td>0.613636</td>\n",
       "      <td>0.616438</td>\n",
       "      <td>0.146243</td>\n",
       "      <td>0.015095</td>\n",
       "      <td>0.002844</td>\n",
       "      <td>0.000317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.165031</td>\n",
       "      <td>0.014287</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_features': 5, 'min_samples_leaf': 7, 'n_...</td>\n",
       "      <td>181</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.617978</td>\n",
       "      <td>0.615960</td>\n",
       "      <td>0.617978</td>\n",
       "      <td>0.615960</td>\n",
       "      <td>0.613636</td>\n",
       "      <td>0.616438</td>\n",
       "      <td>0.011167</td>\n",
       "      <td>0.003649</td>\n",
       "      <td>0.002844</td>\n",
       "      <td>0.000317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.331711</td>\n",
       "      <td>0.044085</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>250</td>\n",
       "      <td>{'max_features': 5, 'min_samples_leaf': 7, 'n_...</td>\n",
       "      <td>181</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.617978</td>\n",
       "      <td>0.615960</td>\n",
       "      <td>0.617978</td>\n",
       "      <td>0.615960</td>\n",
       "      <td>0.613636</td>\n",
       "      <td>0.616438</td>\n",
       "      <td>0.088818</td>\n",
       "      <td>0.027567</td>\n",
       "      <td>0.002844</td>\n",
       "      <td>0.000317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.828802</td>\n",
       "      <td>0.032252</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_features': 5, 'min_samples_leaf': 7, 'n_...</td>\n",
       "      <td>181</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.617978</td>\n",
       "      <td>0.615960</td>\n",
       "      <td>0.617978</td>\n",
       "      <td>0.615960</td>\n",
       "      <td>0.613636</td>\n",
       "      <td>0.616438</td>\n",
       "      <td>0.304483</td>\n",
       "      <td>0.016834</td>\n",
       "      <td>0.002844</td>\n",
       "      <td>0.000317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.361543</td>\n",
       "      <td>0.014687</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_features': 5, 'min_samples_leaf': 5, 'n_...</td>\n",
       "      <td>181</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.617978</td>\n",
       "      <td>0.615960</td>\n",
       "      <td>0.617978</td>\n",
       "      <td>0.615960</td>\n",
       "      <td>0.613636</td>\n",
       "      <td>0.616438</td>\n",
       "      <td>0.157271</td>\n",
       "      <td>0.003926</td>\n",
       "      <td>0.002844</td>\n",
       "      <td>0.000317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.825844</td>\n",
       "      <td>0.105001</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.617035</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_features': 5, 'min_samples_leaf': 7, 'n_...</td>\n",
       "      <td>181</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.617978</td>\n",
       "      <td>0.615960</td>\n",
       "      <td>0.617978</td>\n",
       "      <td>0.615960</td>\n",
       "      <td>0.613636</td>\n",
       "      <td>0.616438</td>\n",
       "      <td>0.324813</td>\n",
       "      <td>0.069494</td>\n",
       "      <td>0.002844</td>\n",
       "      <td>0.002570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows  33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "112       1.105567         0.065243         0.839506          0.870684   \n",
       "111       1.118000         0.026000         0.838384          0.870558   \n",
       "110       0.319600         0.018400         0.838384          0.871181   \n",
       "113       1.775158         0.073948         0.836139          0.869936   \n",
       "108       0.134001         0.007999         0.836139          0.868937   \n",
       "163       0.585534         0.031180         0.836139          0.874549   \n",
       "143       1.748309         0.083600         0.836139          0.869686   \n",
       "109       0.608399         0.028401         0.835017          0.867690   \n",
       "106       1.186821         0.065290         0.835017          0.893379   \n",
       "162       0.154419         0.005432         0.835017          0.872929   \n",
       "116       0.407301         0.019127         0.833895          0.859210   \n",
       "164       0.469792         0.019963         0.833895          0.874424   \n",
       "139       0.421528         0.010070         0.833895          0.869437   \n",
       "166       1.325356         0.059069         0.833895          0.874424   \n",
       "167       2.382435         0.080873         0.833895          0.874674   \n",
       "119       1.687189         0.137257         0.833895          0.859459   \n",
       "140       0.583927         0.032581         0.832772          0.869062   \n",
       "129       1.101200         0.039600         0.832772          0.909217   \n",
       "151       0.535065         0.027220         0.832772          0.914329   \n",
       "157       0.662102         0.031397         0.832772          0.888640   \n",
       "107       1.873608         0.051599         0.832772          0.894376   \n",
       "130       1.340607         0.041423         0.832772          0.908967   \n",
       "141       0.892484         0.025360         0.831650          0.867815   \n",
       "115       0.530183         0.034035         0.831650          0.857590   \n",
       "117       1.050565         0.048719         0.831650          0.858087   \n",
       "134       0.660799         0.015600         0.831650          0.881906   \n",
       "142       1.165100         0.066984         0.831650          0.869935   \n",
       "165       1.289052         0.040023         0.831650          0.874549   \n",
       "175       0.742964         0.014133         0.830527          0.919191   \n",
       "137       2.049325         0.065678         0.830527          0.885024   \n",
       "..             ...              ...              ...               ...   \n",
       "37        0.141201         0.018400         0.803591          0.810326   \n",
       "38        0.590799         0.042400         0.802469          0.812198   \n",
       "40        0.693602         0.070400         0.800224          0.815938   \n",
       "41        0.928000         0.087600         0.800224          0.818931   \n",
       "43        0.277998         0.012800         0.799102          0.800102   \n",
       "36        0.062178         0.005205         0.799102          0.806210   \n",
       "39        0.298800         0.023200         0.797980          0.814066   \n",
       "44        0.185649         0.014836         0.796857          0.801221   \n",
       "47        1.032684         0.106266         0.795735          0.816062   \n",
       "46        0.667662         0.027981         0.794613          0.802219   \n",
       "45        0.504746         0.055248         0.793490          0.803216   \n",
       "42        0.192001         0.018800         0.783389          0.790122   \n",
       "6         0.059206         0.003821         0.629630          0.635629   \n",
       "12        0.057749         0.007008         0.618406          0.622274   \n",
       "18        0.128198         0.017820         0.618406          0.621774   \n",
       "11        0.842400         0.044912         0.618406          0.619404   \n",
       "9         0.520275         0.036718         0.617284          0.616411   \n",
       "10        0.596383         0.047200         0.617284          0.617410   \n",
       "7         0.108758         0.009865         0.616162          0.616286   \n",
       "8         0.197348         0.023447         0.616162          0.616162   \n",
       "13        0.405174         0.045262         0.616162          0.616162   \n",
       "15        0.267010         0.024148         0.616162          0.616162   \n",
       "16        0.702095         0.081219         0.616162          0.616162   \n",
       "17        0.775219         0.051586         0.616162          0.616785   \n",
       "19        0.338970         0.028543         0.616162          0.616162   \n",
       "20        0.165031         0.014287         0.616162          0.616162   \n",
       "21        0.331711         0.044085         0.616162          0.616162   \n",
       "22        0.828802         0.032252         0.616162          0.616162   \n",
       "14        0.361543         0.014687         0.616162          0.616162   \n",
       "23        0.825844         0.105001         0.616162          0.617035   \n",
       "\n",
       "    param_max_features param_min_samples_leaf param_n_estimators  \\\n",
       "112                 50                      5                300   \n",
       "111                 50                      5                250   \n",
       "110                 50                      5                150   \n",
       "113                 50                      5                500   \n",
       "108                 50                      5                 50   \n",
       "163                100                      7                100   \n",
       "143                 75                      7                500   \n",
       "109                 50                      5                100   \n",
       "106                 50                      3                300   \n",
       "162                100                      7                 50   \n",
       "116                 50                      7                150   \n",
       "164                100                      7                150   \n",
       "139                 75                      7                100   \n",
       "166                100                      7                300   \n",
       "167                100                      7                500   \n",
       "119                 50                      7                500   \n",
       "140                 75                      7                150   \n",
       "129                 75                      3                250   \n",
       "151                100                      3                100   \n",
       "157                100                      5                100   \n",
       "107                 50                      3                500   \n",
       "130                 75                      3                300   \n",
       "141                 75                      7                250   \n",
       "115                 50                      7                100   \n",
       "117                 50                      7                250   \n",
       "134                 75                      5                150   \n",
       "142                 75                      7                300   \n",
       "165                100                      7                250   \n",
       "175                125                      3                100   \n",
       "137                 75                      5                500   \n",
       "..                 ...                    ...                ...   \n",
       "37                  10                      5                100   \n",
       "38                  10                      5                150   \n",
       "40                  10                      5                300   \n",
       "41                  10                      5                500   \n",
       "43                  10                      7                100   \n",
       "36                  10                      5                 50   \n",
       "39                  10                      5                250   \n",
       "44                  10                      7                150   \n",
       "47                  10                      7                500   \n",
       "46                  10                      7                300   \n",
       "45                  10                      7                250   \n",
       "42                  10                      7                 50   \n",
       "6                    5                      3                 50   \n",
       "12                   5                      5                 50   \n",
       "18                   5                      7                 50   \n",
       "11                   5                      3                500   \n",
       "9                    5                      3                250   \n",
       "10                   5                      3                300   \n",
       "7                    5                      3                100   \n",
       "8                    5                      3                150   \n",
       "13                   5                      5                100   \n",
       "15                   5                      5                250   \n",
       "16                   5                      5                300   \n",
       "17                   5                      5                500   \n",
       "19                   5                      7                100   \n",
       "20                   5                      7                150   \n",
       "21                   5                      7                250   \n",
       "22                   5                      7                300   \n",
       "14                   5                      5                150   \n",
       "23                   5                      7                500   \n",
       "\n",
       "                                                params  rank_test_score  \\\n",
       "112  {'max_features': 50, 'min_samples_leaf': 5, 'n...                1   \n",
       "111  {'max_features': 50, 'min_samples_leaf': 5, 'n...                2   \n",
       "110  {'max_features': 50, 'min_samples_leaf': 5, 'n...                2   \n",
       "113  {'max_features': 50, 'min_samples_leaf': 5, 'n...                4   \n",
       "108  {'max_features': 50, 'min_samples_leaf': 5, 'n...                4   \n",
       "163  {'max_features': 100, 'min_samples_leaf': 7, '...                4   \n",
       "143  {'max_features': 75, 'min_samples_leaf': 7, 'n...                4   \n",
       "109  {'max_features': 50, 'min_samples_leaf': 5, 'n...                8   \n",
       "106  {'max_features': 50, 'min_samples_leaf': 3, 'n...                8   \n",
       "162  {'max_features': 100, 'min_samples_leaf': 7, '...                8   \n",
       "116  {'max_features': 50, 'min_samples_leaf': 7, 'n...               11   \n",
       "164  {'max_features': 100, 'min_samples_leaf': 7, '...               11   \n",
       "139  {'max_features': 75, 'min_samples_leaf': 7, 'n...               11   \n",
       "166  {'max_features': 100, 'min_samples_leaf': 7, '...               11   \n",
       "167  {'max_features': 100, 'min_samples_leaf': 7, '...               11   \n",
       "119  {'max_features': 50, 'min_samples_leaf': 7, 'n...               11   \n",
       "140  {'max_features': 75, 'min_samples_leaf': 7, 'n...               17   \n",
       "129  {'max_features': 75, 'min_samples_leaf': 3, 'n...               17   \n",
       "151  {'max_features': 100, 'min_samples_leaf': 3, '...               17   \n",
       "157  {'max_features': 100, 'min_samples_leaf': 5, '...               17   \n",
       "107  {'max_features': 50, 'min_samples_leaf': 3, 'n...               17   \n",
       "130  {'max_features': 75, 'min_samples_leaf': 3, 'n...               17   \n",
       "141  {'max_features': 75, 'min_samples_leaf': 7, 'n...               23   \n",
       "115  {'max_features': 50, 'min_samples_leaf': 7, 'n...               23   \n",
       "117  {'max_features': 50, 'min_samples_leaf': 7, 'n...               23   \n",
       "134  {'max_features': 75, 'min_samples_leaf': 5, 'n...               23   \n",
       "142  {'max_features': 75, 'min_samples_leaf': 7, 'n...               23   \n",
       "165  {'max_features': 100, 'min_samples_leaf': 7, '...               23   \n",
       "175  {'max_features': 125, 'min_samples_leaf': 3, '...               29   \n",
       "137  {'max_features': 75, 'min_samples_leaf': 5, 'n...               29   \n",
       "..                                                 ...              ...   \n",
       "37   {'max_features': 10, 'min_samples_leaf': 5, 'n...              162   \n",
       "38   {'max_features': 10, 'min_samples_leaf': 5, 'n...              164   \n",
       "40   {'max_features': 10, 'min_samples_leaf': 5, 'n...              165   \n",
       "41   {'max_features': 10, 'min_samples_leaf': 5, 'n...              165   \n",
       "43   {'max_features': 10, 'min_samples_leaf': 7, 'n...              167   \n",
       "36   {'max_features': 10, 'min_samples_leaf': 5, 'n...              167   \n",
       "39   {'max_features': 10, 'min_samples_leaf': 5, 'n...              169   \n",
       "44   {'max_features': 10, 'min_samples_leaf': 7, 'n...              170   \n",
       "47   {'max_features': 10, 'min_samples_leaf': 7, 'n...              171   \n",
       "46   {'max_features': 10, 'min_samples_leaf': 7, 'n...              172   \n",
       "45   {'max_features': 10, 'min_samples_leaf': 7, 'n...              173   \n",
       "42   {'max_features': 10, 'min_samples_leaf': 7, 'n...              174   \n",
       "6    {'max_features': 5, 'min_samples_leaf': 3, 'n_...              175   \n",
       "12   {'max_features': 5, 'min_samples_leaf': 5, 'n_...              176   \n",
       "18   {'max_features': 5, 'min_samples_leaf': 7, 'n_...              176   \n",
       "11   {'max_features': 5, 'min_samples_leaf': 3, 'n_...              176   \n",
       "9    {'max_features': 5, 'min_samples_leaf': 3, 'n_...              179   \n",
       "10   {'max_features': 5, 'min_samples_leaf': 3, 'n_...              179   \n",
       "7    {'max_features': 5, 'min_samples_leaf': 3, 'n_...              181   \n",
       "8    {'max_features': 5, 'min_samples_leaf': 3, 'n_...              181   \n",
       "13   {'max_features': 5, 'min_samples_leaf': 5, 'n_...              181   \n",
       "15   {'max_features': 5, 'min_samples_leaf': 5, 'n_...              181   \n",
       "16   {'max_features': 5, 'min_samples_leaf': 5, 'n_...              181   \n",
       "17   {'max_features': 5, 'min_samples_leaf': 5, 'n_...              181   \n",
       "19   {'max_features': 5, 'min_samples_leaf': 7, 'n_...              181   \n",
       "20   {'max_features': 5, 'min_samples_leaf': 7, 'n_...              181   \n",
       "21   {'max_features': 5, 'min_samples_leaf': 7, 'n_...              181   \n",
       "22   {'max_features': 5, 'min_samples_leaf': 7, 'n_...              181   \n",
       "14   {'max_features': 5, 'min_samples_leaf': 5, 'n_...              181   \n",
       "23   {'max_features': 5, 'min_samples_leaf': 7, 'n_...              181   \n",
       "\n",
       "     split0_test_score       ...         split7_test_score  \\\n",
       "112           0.811111       ...                  0.786517   \n",
       "111           0.822222       ...                  0.786517   \n",
       "110           0.800000       ...                  0.786517   \n",
       "113           0.811111       ...                  0.786517   \n",
       "108           0.788889       ...                  0.786517   \n",
       "163           0.800000       ...                  0.797753   \n",
       "143           0.811111       ...                  0.786517   \n",
       "109           0.800000       ...                  0.786517   \n",
       "106           0.822222       ...                  0.786517   \n",
       "162           0.788889       ...                  0.797753   \n",
       "116           0.811111       ...                  0.775281   \n",
       "164           0.800000       ...                  0.797753   \n",
       "139           0.800000       ...                  0.786517   \n",
       "166           0.800000       ...                  0.786517   \n",
       "167           0.811111       ...                  0.775281   \n",
       "119           0.811111       ...                  0.775281   \n",
       "140           0.811111       ...                  0.786517   \n",
       "129           0.822222       ...                  0.764045   \n",
       "151           0.800000       ...                  0.775281   \n",
       "157           0.833333       ...                  0.797753   \n",
       "107           0.811111       ...                  0.786517   \n",
       "130           0.822222       ...                  0.764045   \n",
       "141           0.811111       ...                  0.786517   \n",
       "115           0.822222       ...                  0.775281   \n",
       "117           0.811111       ...                  0.775281   \n",
       "134           0.822222       ...                  0.786517   \n",
       "142           0.811111       ...                  0.786517   \n",
       "165           0.800000       ...                  0.786517   \n",
       "175           0.788889       ...                  0.764045   \n",
       "137           0.811111       ...                  0.775281   \n",
       "..                 ...       ...                       ...   \n",
       "37            0.811111       ...                  0.786517   \n",
       "38            0.811111       ...                  0.786517   \n",
       "40            0.788889       ...                  0.786517   \n",
       "41            0.777778       ...                  0.764045   \n",
       "43            0.800000       ...                  0.786517   \n",
       "36            0.788889       ...                  0.797753   \n",
       "39            0.777778       ...                  0.786517   \n",
       "44            0.755556       ...                  0.786517   \n",
       "47            0.766667       ...                  0.764045   \n",
       "46            0.755556       ...                  0.786517   \n",
       "45            0.744444       ...                  0.786517   \n",
       "42            0.788889       ...                  0.786517   \n",
       "6             0.644444       ...                  0.617978   \n",
       "12            0.611111       ...                  0.617978   \n",
       "18            0.611111       ...                  0.617978   \n",
       "11            0.611111       ...                  0.617978   \n",
       "9             0.611111       ...                  0.617978   \n",
       "10            0.611111       ...                  0.617978   \n",
       "7             0.611111       ...                  0.617978   \n",
       "8             0.611111       ...                  0.617978   \n",
       "13            0.611111       ...                  0.617978   \n",
       "15            0.611111       ...                  0.617978   \n",
       "16            0.611111       ...                  0.617978   \n",
       "17            0.611111       ...                  0.617978   \n",
       "19            0.611111       ...                  0.617978   \n",
       "20            0.611111       ...                  0.617978   \n",
       "21            0.611111       ...                  0.617978   \n",
       "22            0.611111       ...                  0.617978   \n",
       "14            0.611111       ...                  0.617978   \n",
       "23            0.611111       ...                  0.617978   \n",
       "\n",
       "     split7_train_score  split8_test_score  split8_train_score  \\\n",
       "112            0.870324           0.876404            0.866584   \n",
       "111            0.870324           0.865169            0.866584   \n",
       "110            0.872818           0.876404            0.869077   \n",
       "113            0.867830           0.865169            0.864090   \n",
       "108            0.871571           0.876404            0.866584   \n",
       "163            0.871571           0.876404            0.865337   \n",
       "143            0.871571           0.865169            0.865337   \n",
       "109            0.869077           0.876404            0.860349   \n",
       "106            0.892768           0.876404            0.887781   \n",
       "162            0.871571           0.876404            0.869077   \n",
       "116            0.860349           0.853933            0.852868   \n",
       "164            0.871571           0.865169            0.864090   \n",
       "139            0.870324           0.876404            0.865337   \n",
       "166            0.871571           0.865169            0.866584   \n",
       "167            0.874065           0.876404            0.866584   \n",
       "119            0.859102           0.876404            0.852868   \n",
       "140            0.871571           0.865169            0.860349   \n",
       "129            0.915212           0.865169            0.900249   \n",
       "151            0.915212           0.876404            0.908978   \n",
       "157            0.887781           0.853933            0.879052   \n",
       "107            0.892768           0.865169            0.890274   \n",
       "130            0.917706           0.865169            0.902743   \n",
       "141            0.870324           0.853933            0.862843   \n",
       "115            0.857855           0.853933            0.849127   \n",
       "117            0.857855           0.853933            0.850374   \n",
       "134            0.882793           0.853933            0.880299   \n",
       "142            0.870324           0.853933            0.865337   \n",
       "165            0.872818           0.853933            0.866584   \n",
       "175            0.923940           0.876404            0.921446   \n",
       "137            0.881546           0.853933            0.879052   \n",
       "..                  ...                ...                 ...   \n",
       "37             0.807980           0.831461            0.812968   \n",
       "38             0.810474           0.820225            0.809227   \n",
       "40             0.822943           0.820225            0.816708   \n",
       "41             0.819202           0.808989            0.819202   \n",
       "43             0.810474           0.808989            0.794264   \n",
       "36             0.815461           0.831461            0.819202   \n",
       "39             0.824190           0.820225            0.814214   \n",
       "44             0.807980           0.808989            0.785536   \n",
       "47             0.827930           0.808989            0.816708   \n",
       "46             0.811721           0.808989            0.789277   \n",
       "45             0.810474           0.808989            0.788030   \n",
       "42             0.812968           0.808989            0.807980   \n",
       "6              0.615960           0.617978            0.615960   \n",
       "12             0.615960           0.617978            0.615960   \n",
       "18             0.615960           0.617978            0.615960   \n",
       "11             0.615960           0.617978            0.615960   \n",
       "9              0.615960           0.617978            0.615960   \n",
       "10             0.615960           0.617978            0.615960   \n",
       "7              0.615960           0.617978            0.615960   \n",
       "8              0.615960           0.617978            0.615960   \n",
       "13             0.615960           0.617978            0.615960   \n",
       "15             0.615960           0.617978            0.615960   \n",
       "16             0.615960           0.617978            0.615960   \n",
       "17             0.615960           0.617978            0.615960   \n",
       "19             0.615960           0.617978            0.615960   \n",
       "20             0.615960           0.617978            0.615960   \n",
       "21             0.615960           0.617978            0.615960   \n",
       "22             0.615960           0.617978            0.615960   \n",
       "14             0.615960           0.617978            0.615960   \n",
       "23             0.615960           0.617978            0.615960   \n",
       "\n",
       "     split9_test_score  split9_train_score  std_fit_time  std_score_time  \\\n",
       "112           0.863636            0.864259      0.270026        0.045878   \n",
       "111           0.863636            0.869240      0.301087        0.004472   \n",
       "110           0.875000            0.869240      0.012706        0.008617   \n",
       "113           0.863636            0.865504      0.042311        0.042141   \n",
       "108           0.852273            0.865504      0.037535        0.005933   \n",
       "163           0.829545            0.872976      0.235594        0.017446   \n",
       "143           0.863636            0.865504      0.133755        0.069384   \n",
       "109           0.863636            0.866750      0.190793        0.018195   \n",
       "106           0.863636            0.890411      0.291438        0.044983   \n",
       "162           0.863636            0.874222      0.060014        0.004504   \n",
       "116           0.875000            0.855542      0.167952        0.011285   \n",
       "164           0.852273            0.871731      0.143200        0.014938   \n",
       "139           0.863636            0.861768      0.187481        0.000010   \n",
       "166           0.852273            0.872976      0.248836        0.043731   \n",
       "167           0.840909            0.870486      0.306166        0.063634   \n",
       "119           0.875000            0.860523      0.061936        0.072854   \n",
       "140           0.852273            0.861768      0.311181        0.022358   \n",
       "129           0.863636            0.900374      0.284998        0.031264   \n",
       "151           0.852273            0.911582      0.300366        0.016299   \n",
       "157           0.840909            0.887920      0.158000        0.017764   \n",
       "107           0.852273            0.892902      0.018006        0.012321   \n",
       "130           0.863636            0.900374      0.303963        0.029146   \n",
       "141           0.875000            0.860523      0.306271        0.003939   \n",
       "115           0.863636            0.850560      0.158624        0.017311   \n",
       "117           0.875000            0.860523      0.287935        0.036467   \n",
       "134           0.840909            0.871731      0.291264        0.001200   \n",
       "142           0.863636            0.865504      0.288183        0.047238   \n",
       "165           0.852273            0.874222      0.211892        0.030911   \n",
       "175           0.852273            0.919054      0.353836        0.011559   \n",
       "137           0.840909            0.879203      0.103773        0.049282   \n",
       "..                 ...                 ...           ...             ...   \n",
       "37            0.795455            0.809465      0.027426        0.014334   \n",
       "38            0.795455            0.810710      0.131735        0.024606   \n",
       "40            0.795455            0.810710      0.298761        0.043531   \n",
       "41            0.818182            0.816936      0.257669        0.080587   \n",
       "43            0.806818            0.808219      0.156217        0.010553   \n",
       "36            0.806818            0.810710      0.003166        0.002566   \n",
       "39            0.795455            0.813200      0.016203        0.001600   \n",
       "44            0.806818            0.811955      0.009454        0.008060   \n",
       "47            0.806818            0.814446      0.275755        0.078957   \n",
       "46            0.806818            0.809465      0.280672        0.003174   \n",
       "45            0.795455            0.809465      0.285632        0.039668   \n",
       "42            0.795455            0.810710      0.115738        0.012400   \n",
       "6             0.613636            0.616438      0.005433        0.004355   \n",
       "12            0.613636            0.616438      0.002375        0.002059   \n",
       "18            0.613636            0.616438      0.072540        0.012709   \n",
       "11            0.613636            0.616438      0.323730        0.003924   \n",
       "9             0.613636            0.616438      0.281288        0.029907   \n",
       "10            0.613636            0.616438      0.341295        0.038441   \n",
       "7             0.613636            0.616438      0.004007        0.000613   \n",
       "8             0.613636            0.616438      0.097633        0.019453   \n",
       "13            0.613636            0.616438      0.087687        0.006698   \n",
       "15            0.613636            0.616438      0.007072        0.005833   \n",
       "16            0.613636            0.616438      0.276842        0.045281   \n",
       "17            0.613636            0.616438      0.297468        0.013616   \n",
       "19            0.613636            0.616438      0.146243        0.015095   \n",
       "20            0.613636            0.616438      0.011167        0.003649   \n",
       "21            0.613636            0.616438      0.088818        0.027567   \n",
       "22            0.613636            0.616438      0.304483        0.016834   \n",
       "14            0.613636            0.616438      0.157271        0.003926   \n",
       "23            0.613636            0.616438      0.324813        0.069494   \n",
       "\n",
       "     std_test_score  std_train_score  \n",
       "112        0.044160         0.006539  \n",
       "111        0.042516         0.005798  \n",
       "110        0.045199         0.006028  \n",
       "113        0.043643         0.006023  \n",
       "108        0.044947         0.005245  \n",
       "163        0.050083         0.005910  \n",
       "143        0.047516         0.005668  \n",
       "109        0.043451         0.007560  \n",
       "106        0.049566         0.004447  \n",
       "162        0.045657         0.006688  \n",
       "116        0.044075         0.006521  \n",
       "164        0.047049         0.006269  \n",
       "139        0.047854         0.005705  \n",
       "166        0.047891         0.005800  \n",
       "167        0.048720         0.005610  \n",
       "119        0.045438         0.005265  \n",
       "140        0.044057         0.006898  \n",
       "129        0.053584         0.006718  \n",
       "151        0.055300         0.003243  \n",
       "157        0.043712         0.004622  \n",
       "107        0.048681         0.003149  \n",
       "130        0.052634         0.006519  \n",
       "141        0.045225         0.006962  \n",
       "115        0.042140         0.007204  \n",
       "117        0.042393         0.006595  \n",
       "134        0.048656         0.005209  \n",
       "142        0.044463         0.006581  \n",
       "165        0.047378         0.005306  \n",
       "175        0.050785         0.004403  \n",
       "137        0.049713         0.004743  \n",
       "..              ...              ...  \n",
       "37         0.030029         0.007127  \n",
       "38         0.034328         0.005848  \n",
       "40         0.034871         0.004106  \n",
       "41         0.035283         0.003805  \n",
       "43         0.027231         0.012033  \n",
       "36         0.036606         0.017280  \n",
       "39         0.034880         0.005623  \n",
       "44         0.034265         0.008753  \n",
       "47         0.035922         0.006178  \n",
       "46         0.038882         0.007757  \n",
       "45         0.038268         0.007504  \n",
       "42         0.033396         0.021807  \n",
       "6          0.018066         0.029129  \n",
       "12         0.007851         0.012466  \n",
       "18         0.007851         0.012803  \n",
       "11         0.007851         0.005592  \n",
       "9          0.004849         0.000499  \n",
       "10         0.004849         0.002793  \n",
       "7          0.002844         0.000436  \n",
       "8          0.002844         0.000317  \n",
       "13         0.002844         0.000317  \n",
       "15         0.002844         0.000317  \n",
       "16         0.002844         0.000317  \n",
       "17         0.002844         0.001830  \n",
       "19         0.002844         0.000317  \n",
       "20         0.002844         0.000317  \n",
       "21         0.002844         0.000317  \n",
       "22         0.002844         0.000317  \n",
       "14         0.002844         0.000317  \n",
       "23         0.002844         0.002570  \n",
       "\n",
       "[192 rows x 33 columns]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "tstart = time.time()\n",
    "params = {'n_estimators' : [50, 100, 150, 250, 300, 500],\\\n",
    "         'min_samples_leaf' : [1, 3, 5, 7],\\\n",
    "         'max_features' : [5, 10, 15, 25, 50, 75, 100, 125]}\n",
    "\n",
    "clf = RandomForestClassifier(random_state = 0)\n",
    "cv_fit = GridSearchCV(clf, params, scoring = 'accuracy', cv = 10, n_jobs = -1)\n",
    "results = cv_fit.fit(train_data_final_ar, y_train)\n",
    "\n",
    "tdiff = time.time() - tstart\n",
    "print(\"Took \" + str(tdiff) + \" seconds\")\n",
    "pd.DataFrame(results.cv_results_).sort_values(['rank_test_score'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "So running this actually killed about 6% of my laptop's battery and took quite a bit, so we know that this was some hefty calculations happening on the back end. But with our best settings we can now have an accuracy of about 87%, which is an improvement over our logistic regression model. \n",
    "\n",
    "A few notes- \n",
    "\n",
    "* I'm intentionally being lazy and not doing too much visualization at the moment... If I were to try to explain why each of these models is doing what it's doing, I haven't really presented a convincing case here. \n",
    "* We have done cross-validation in order to evaluate our data, but the real use case is with the test set. So we would really want to predict on the test set, submit to kaggle, and then see what our results are in order to really see how good we have done. Ideally, cross validation should shot pretty similar results to the evaluation on the test set, but you can't know that till you do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johnb\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1,\n",
       "       1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0,\n",
       "       0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for kaggle submission\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(random_state = 0)\n",
    "classifier_fit = clf.fit(train_data_final_ar, y_train)\n",
    "test_predictions = clf.predict(test_data_final_ar)\n",
    "test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>ticket_prefix</th>\n",
       "      <th>ticket_num_digits</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Mrs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Mrs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>897</td>\n",
       "      <td>3</td>\n",
       "      <td>Svensson, Mr. Johan Cervin</td>\n",
       "      <td>male</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7538</td>\n",
       "      <td>9.2250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>898</td>\n",
       "      <td>3</td>\n",
       "      <td>Connolly, Miss. Kate</td>\n",
       "      <td>female</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330972</td>\n",
       "      <td>7.6292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Miss.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>899</td>\n",
       "      <td>2</td>\n",
       "      <td>Caldwell, Mr. Albert Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>248738</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>900</td>\n",
       "      <td>3</td>\n",
       "      <td>Abrahim, Mrs. Joseph (Sophie Halaut Easu)</td>\n",
       "      <td>female</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2657</td>\n",
       "      <td>7.2292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Mrs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>901</td>\n",
       "      <td>3</td>\n",
       "      <td>Davies, Mr. John Samuel</td>\n",
       "      <td>male</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>A/4 48871</td>\n",
       "      <td>24.1500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>902</td>\n",
       "      <td>3</td>\n",
       "      <td>Ilieff, Mr. Ylio</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349220</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>903</td>\n",
       "      <td>1</td>\n",
       "      <td>Jones, Mr. Charles Cresson</td>\n",
       "      <td>male</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>694</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>904</td>\n",
       "      <td>1</td>\n",
       "      <td>Snyder, Mrs. John Pillsbury (Nelle Stevenson)</td>\n",
       "      <td>female</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>21228</td>\n",
       "      <td>82.2667</td>\n",
       "      <td>B45</td>\n",
       "      <td>S</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Mrs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>905</td>\n",
       "      <td>2</td>\n",
       "      <td>Howard, Mr. Benjamin</td>\n",
       "      <td>male</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24065</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>906</td>\n",
       "      <td>1</td>\n",
       "      <td>Chaffee, Mrs. Herbert Fuller (Carrie Constance...</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>W.E.P. 5734</td>\n",
       "      <td>61.1750</td>\n",
       "      <td>E31</td>\n",
       "      <td>S</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Mrs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>907</td>\n",
       "      <td>2</td>\n",
       "      <td>del Carlo, Mrs. Sebastiano (Argenia Genovesi)</td>\n",
       "      <td>female</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>SC/PARIS 2167</td>\n",
       "      <td>27.7208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Mrs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>908</td>\n",
       "      <td>2</td>\n",
       "      <td>Keane, Mr. Daniel</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>233734</td>\n",
       "      <td>12.3500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>909</td>\n",
       "      <td>3</td>\n",
       "      <td>Assaf, Mr. Gerios</td>\n",
       "      <td>male</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2692</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>910</td>\n",
       "      <td>3</td>\n",
       "      <td>Ilmakangas, Miss. Ida Livija</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101270</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Miss.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>911</td>\n",
       "      <td>3</td>\n",
       "      <td>Assaf Khalil, Mrs. Mariana (Miriam\")\"</td>\n",
       "      <td>female</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2696</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Mrs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>912</td>\n",
       "      <td>1</td>\n",
       "      <td>Rothschild, Mr. Martin</td>\n",
       "      <td>male</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17603</td>\n",
       "      <td>59.4000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>913</td>\n",
       "      <td>3</td>\n",
       "      <td>Olsen, Master. Artur Karl</td>\n",
       "      <td>male</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>C 17368</td>\n",
       "      <td>3.1708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Master.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>914</td>\n",
       "      <td>1</td>\n",
       "      <td>Flegenheim, Mrs. Alfred (Antoinette)</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17598</td>\n",
       "      <td>31.6833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Mrs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>915</td>\n",
       "      <td>1</td>\n",
       "      <td>Williams, Mr. Richard Norris II</td>\n",
       "      <td>male</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PC 17597</td>\n",
       "      <td>61.3792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>916</td>\n",
       "      <td>1</td>\n",
       "      <td>Ryerson, Mrs. Arthur Larned (Emily Maria Borie)</td>\n",
       "      <td>female</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>PC 17608</td>\n",
       "      <td>262.3750</td>\n",
       "      <td>B57 B59 B63 B66</td>\n",
       "      <td>C</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Mrs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>917</td>\n",
       "      <td>3</td>\n",
       "      <td>Robins, Mr. Alexander A</td>\n",
       "      <td>male</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5. 3337</td>\n",
       "      <td>14.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>918</td>\n",
       "      <td>1</td>\n",
       "      <td>Ostby, Miss. Helene Ragnhild</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>113509</td>\n",
       "      <td>61.9792</td>\n",
       "      <td>B36</td>\n",
       "      <td>C</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Miss.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>919</td>\n",
       "      <td>3</td>\n",
       "      <td>Daher, Mr. Shedid</td>\n",
       "      <td>male</td>\n",
       "      <td>22.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2698</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>920</td>\n",
       "      <td>1</td>\n",
       "      <td>Brady, Mr. John Bertram</td>\n",
       "      <td>male</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113054</td>\n",
       "      <td>30.5000</td>\n",
       "      <td>A21</td>\n",
       "      <td>S</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>921</td>\n",
       "      <td>3</td>\n",
       "      <td>Samaan, Mr. Elias</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2662</td>\n",
       "      <td>21.6792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>1280</td>\n",
       "      <td>3</td>\n",
       "      <td>Canavan, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>364858</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>1281</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Master. Paul Folke</td>\n",
       "      <td>male</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Master.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>1282</td>\n",
       "      <td>1</td>\n",
       "      <td>Payne, Mr. Vivian Ponsonby</td>\n",
       "      <td>male</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12749</td>\n",
       "      <td>93.5000</td>\n",
       "      <td>B24</td>\n",
       "      <td>S</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>1283</td>\n",
       "      <td>1</td>\n",
       "      <td>Lines, Mrs. Ernest H (Elizabeth Lindsey James)</td>\n",
       "      <td>female</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PC 17592</td>\n",
       "      <td>39.4000</td>\n",
       "      <td>D28</td>\n",
       "      <td>S</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Mrs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>1284</td>\n",
       "      <td>3</td>\n",
       "      <td>Abbott, Master. Eugene Joseph</td>\n",
       "      <td>male</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>C.A. 2673</td>\n",
       "      <td>20.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Master.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>1285</td>\n",
       "      <td>2</td>\n",
       "      <td>Gilbert, Mr. William</td>\n",
       "      <td>male</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C.A. 30769</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>1286</td>\n",
       "      <td>3</td>\n",
       "      <td>Kink-Heilmann, Mr. Anton</td>\n",
       "      <td>male</td>\n",
       "      <td>29.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>315153</td>\n",
       "      <td>22.0250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>1287</td>\n",
       "      <td>1</td>\n",
       "      <td>Smith, Mrs. Lucien Philip (Mary Eloise Hughes)</td>\n",
       "      <td>female</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13695</td>\n",
       "      <td>60.0000</td>\n",
       "      <td>C31</td>\n",
       "      <td>S</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Mrs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>1288</td>\n",
       "      <td>3</td>\n",
       "      <td>Colbert, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>371109</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>1289</td>\n",
       "      <td>1</td>\n",
       "      <td>Frolicher-Stehli, Mrs. Maxmillian (Margaretha ...</td>\n",
       "      <td>female</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13567</td>\n",
       "      <td>79.2000</td>\n",
       "      <td>B41</td>\n",
       "      <td>C</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Mrs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>1290</td>\n",
       "      <td>3</td>\n",
       "      <td>Larsson-Rondberg, Mr. Edvard A</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>347065</td>\n",
       "      <td>7.7750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>1291</td>\n",
       "      <td>3</td>\n",
       "      <td>Conlon, Mr. Thomas Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21332</td>\n",
       "      <td>7.7333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>1292</td>\n",
       "      <td>1</td>\n",
       "      <td>Bonnell, Miss. Caroline</td>\n",
       "      <td>female</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36928</td>\n",
       "      <td>164.8667</td>\n",
       "      <td>C7</td>\n",
       "      <td>S</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Miss.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>1293</td>\n",
       "      <td>2</td>\n",
       "      <td>Gale, Mr. Harry</td>\n",
       "      <td>male</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28664</td>\n",
       "      <td>21.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>1294</td>\n",
       "      <td>1</td>\n",
       "      <td>Gibson, Miss. Dorothy Winifred</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112378</td>\n",
       "      <td>59.4000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Miss.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>1295</td>\n",
       "      <td>1</td>\n",
       "      <td>Carrau, Mr. Jose Pedro</td>\n",
       "      <td>male</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113059</td>\n",
       "      <td>47.1000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>1296</td>\n",
       "      <td>1</td>\n",
       "      <td>Frauenthal, Mr. Isaac Gerald</td>\n",
       "      <td>male</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17765</td>\n",
       "      <td>27.7208</td>\n",
       "      <td>D40</td>\n",
       "      <td>C</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>1297</td>\n",
       "      <td>2</td>\n",
       "      <td>Nourney, Mr. Alfred (Baron von Drachstedt\")\"</td>\n",
       "      <td>male</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SC/PARIS 2166</td>\n",
       "      <td>13.8625</td>\n",
       "      <td>D38</td>\n",
       "      <td>C</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>1298</td>\n",
       "      <td>2</td>\n",
       "      <td>Ware, Mr. William Jeffery</td>\n",
       "      <td>male</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28666</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>1299</td>\n",
       "      <td>1</td>\n",
       "      <td>Widener, Mr. George Dunton</td>\n",
       "      <td>male</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>113503</td>\n",
       "      <td>211.5000</td>\n",
       "      <td>C80</td>\n",
       "      <td>C</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>1300</td>\n",
       "      <td>3</td>\n",
       "      <td>Riordan, Miss. Johanna Hannah\"\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>334915</td>\n",
       "      <td>7.7208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Miss.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>1301</td>\n",
       "      <td>3</td>\n",
       "      <td>Peacock, Miss. Treasteall</td>\n",
       "      <td>female</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>SOTON/O.Q. 3101315</td>\n",
       "      <td>13.7750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Miss.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>1302</td>\n",
       "      <td>3</td>\n",
       "      <td>Naughton, Miss. Hannah</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>365237</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Miss.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>1303</td>\n",
       "      <td>1</td>\n",
       "      <td>Minahan, Mrs. William Edward (Lillian E Thorpe)</td>\n",
       "      <td>female</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19928</td>\n",
       "      <td>90.0000</td>\n",
       "      <td>C78</td>\n",
       "      <td>Q</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Mrs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>1304</td>\n",
       "      <td>3</td>\n",
       "      <td>Henriksson, Miss. Jenny Lovisa</td>\n",
       "      <td>female</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>347086</td>\n",
       "      <td>7.7750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Miss.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>3</td>\n",
       "      <td>Spector, Mr. Woolf</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A.5. 3236</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "      <td>Oliva y Ocana, Dona. Fermina</td>\n",
       "      <td>female</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17758</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>C105</td>\n",
       "      <td>C</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Dona.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>3</td>\n",
       "      <td>Saether, Mr. Simon Sivertsen</td>\n",
       "      <td>male</td>\n",
       "      <td>38.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SOTON/O.Q. 3101262</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>3</td>\n",
       "      <td>Ware, Mr. Frederick</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>359309</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>3</td>\n",
       "      <td>Peter, Master. Michael J</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2668</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Master.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows  14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Pclass                                               Name  \\\n",
       "0            892       3                                   Kelly, Mr. James   \n",
       "1            893       3                   Wilkes, Mrs. James (Ellen Needs)   \n",
       "2            894       2                          Myles, Mr. Thomas Francis   \n",
       "3            895       3                                   Wirz, Mr. Albert   \n",
       "4            896       3       Hirvonen, Mrs. Alexander (Helga E Lindqvist)   \n",
       "5            897       3                         Svensson, Mr. Johan Cervin   \n",
       "6            898       3                               Connolly, Miss. Kate   \n",
       "7            899       2                       Caldwell, Mr. Albert Francis   \n",
       "8            900       3          Abrahim, Mrs. Joseph (Sophie Halaut Easu)   \n",
       "9            901       3                            Davies, Mr. John Samuel   \n",
       "10           902       3                                   Ilieff, Mr. Ylio   \n",
       "11           903       1                         Jones, Mr. Charles Cresson   \n",
       "12           904       1      Snyder, Mrs. John Pillsbury (Nelle Stevenson)   \n",
       "13           905       2                               Howard, Mr. Benjamin   \n",
       "14           906       1  Chaffee, Mrs. Herbert Fuller (Carrie Constance...   \n",
       "15           907       2      del Carlo, Mrs. Sebastiano (Argenia Genovesi)   \n",
       "16           908       2                                  Keane, Mr. Daniel   \n",
       "17           909       3                                  Assaf, Mr. Gerios   \n",
       "18           910       3                       Ilmakangas, Miss. Ida Livija   \n",
       "19           911       3              Assaf Khalil, Mrs. Mariana (Miriam\")\"   \n",
       "20           912       1                             Rothschild, Mr. Martin   \n",
       "21           913       3                          Olsen, Master. Artur Karl   \n",
       "22           914       1               Flegenheim, Mrs. Alfred (Antoinette)   \n",
       "23           915       1                    Williams, Mr. Richard Norris II   \n",
       "24           916       1    Ryerson, Mrs. Arthur Larned (Emily Maria Borie)   \n",
       "25           917       3                            Robins, Mr. Alexander A   \n",
       "26           918       1                       Ostby, Miss. Helene Ragnhild   \n",
       "27           919       3                                  Daher, Mr. Shedid   \n",
       "28           920       1                            Brady, Mr. John Bertram   \n",
       "29           921       3                                  Samaan, Mr. Elias   \n",
       "..           ...     ...                                                ...   \n",
       "388         1280       3                               Canavan, Mr. Patrick   \n",
       "389         1281       3                        Palsson, Master. Paul Folke   \n",
       "390         1282       1                         Payne, Mr. Vivian Ponsonby   \n",
       "391         1283       1     Lines, Mrs. Ernest H (Elizabeth Lindsey James)   \n",
       "392         1284       3                      Abbott, Master. Eugene Joseph   \n",
       "393         1285       2                               Gilbert, Mr. William   \n",
       "394         1286       3                           Kink-Heilmann, Mr. Anton   \n",
       "395         1287       1     Smith, Mrs. Lucien Philip (Mary Eloise Hughes)   \n",
       "396         1288       3                               Colbert, Mr. Patrick   \n",
       "397         1289       1  Frolicher-Stehli, Mrs. Maxmillian (Margaretha ...   \n",
       "398         1290       3                     Larsson-Rondberg, Mr. Edvard A   \n",
       "399         1291       3                           Conlon, Mr. Thomas Henry   \n",
       "400         1292       1                            Bonnell, Miss. Caroline   \n",
       "401         1293       2                                    Gale, Mr. Harry   \n",
       "402         1294       1                     Gibson, Miss. Dorothy Winifred   \n",
       "403         1295       1                             Carrau, Mr. Jose Pedro   \n",
       "404         1296       1                       Frauenthal, Mr. Isaac Gerald   \n",
       "405         1297       2       Nourney, Mr. Alfred (Baron von Drachstedt\")\"   \n",
       "406         1298       2                          Ware, Mr. William Jeffery   \n",
       "407         1299       1                         Widener, Mr. George Dunton   \n",
       "408         1300       3                    Riordan, Miss. Johanna Hannah\"\"   \n",
       "409         1301       3                          Peacock, Miss. Treasteall   \n",
       "410         1302       3                             Naughton, Miss. Hannah   \n",
       "411         1303       1    Minahan, Mrs. William Edward (Lillian E Thorpe)   \n",
       "412         1304       3                     Henriksson, Miss. Jenny Lovisa   \n",
       "413         1305       3                                 Spector, Mr. Woolf   \n",
       "414         1306       1                       Oliva y Ocana, Dona. Fermina   \n",
       "415         1307       3                       Saether, Mr. Simon Sivertsen   \n",
       "416         1308       3                                Ware, Mr. Frederick   \n",
       "417         1309       3                           Peter, Master. Michael J   \n",
       "\n",
       "        Sex   Age  SibSp  Parch              Ticket      Fare  \\\n",
       "0      male  34.5      0      0              330911    7.8292   \n",
       "1    female  47.0      1      0              363272    7.0000   \n",
       "2      male  62.0      0      0              240276    9.6875   \n",
       "3      male  27.0      0      0              315154    8.6625   \n",
       "4    female  22.0      1      1             3101298   12.2875   \n",
       "5      male  14.0      0      0                7538    9.2250   \n",
       "6    female  30.0      0      0              330972    7.6292   \n",
       "7      male  26.0      1      1              248738   29.0000   \n",
       "8    female  18.0      0      0                2657    7.2292   \n",
       "9      male  21.0      2      0           A/4 48871   24.1500   \n",
       "10     male   NaN      0      0              349220    7.8958   \n",
       "11     male  46.0      0      0                 694   26.0000   \n",
       "12   female  23.0      1      0               21228   82.2667   \n",
       "13     male  63.0      1      0               24065   26.0000   \n",
       "14   female  47.0      1      0         W.E.P. 5734   61.1750   \n",
       "15   female  24.0      1      0       SC/PARIS 2167   27.7208   \n",
       "16     male  35.0      0      0              233734   12.3500   \n",
       "17     male  21.0      0      0                2692    7.2250   \n",
       "18   female  27.0      1      0    STON/O2. 3101270    7.9250   \n",
       "19   female  45.0      0      0                2696    7.2250   \n",
       "20     male  55.0      1      0            PC 17603   59.4000   \n",
       "21     male   9.0      0      1             C 17368    3.1708   \n",
       "22   female   NaN      0      0            PC 17598   31.6833   \n",
       "23     male  21.0      0      1            PC 17597   61.3792   \n",
       "24   female  48.0      1      3            PC 17608  262.3750   \n",
       "25     male  50.0      1      0           A/5. 3337   14.5000   \n",
       "26   female  22.0      0      1              113509   61.9792   \n",
       "27     male  22.5      0      0                2698    7.2250   \n",
       "28     male  41.0      0      0              113054   30.5000   \n",
       "29     male   NaN      2      0                2662   21.6792   \n",
       "..      ...   ...    ...    ...                 ...       ...   \n",
       "388    male  21.0      0      0              364858    7.7500   \n",
       "389    male   6.0      3      1              349909   21.0750   \n",
       "390    male  23.0      0      0               12749   93.5000   \n",
       "391  female  51.0      0      1            PC 17592   39.4000   \n",
       "392    male  13.0      0      2           C.A. 2673   20.2500   \n",
       "393    male  47.0      0      0          C.A. 30769   10.5000   \n",
       "394    male  29.0      3      1              315153   22.0250   \n",
       "395  female  18.0      1      0               13695   60.0000   \n",
       "396    male  24.0      0      0              371109    7.2500   \n",
       "397  female  48.0      1      1               13567   79.2000   \n",
       "398    male  22.0      0      0              347065    7.7750   \n",
       "399    male  31.0      0      0               21332    7.7333   \n",
       "400  female  30.0      0      0               36928  164.8667   \n",
       "401    male  38.0      1      0               28664   21.0000   \n",
       "402  female  22.0      0      1              112378   59.4000   \n",
       "403    male  17.0      0      0              113059   47.1000   \n",
       "404    male  43.0      1      0               17765   27.7208   \n",
       "405    male  20.0      0      0       SC/PARIS 2166   13.8625   \n",
       "406    male  23.0      1      0               28666   10.5000   \n",
       "407    male  50.0      1      1              113503  211.5000   \n",
       "408  female   NaN      0      0              334915    7.7208   \n",
       "409  female   3.0      1      1  SOTON/O.Q. 3101315   13.7750   \n",
       "410  female   NaN      0      0              365237    7.7500   \n",
       "411  female  37.0      1      0               19928   90.0000   \n",
       "412  female  28.0      0      0              347086    7.7750   \n",
       "413    male   NaN      0      0           A.5. 3236    8.0500   \n",
       "414  female  39.0      0      0            PC 17758  108.9000   \n",
       "415    male  38.5      0      0  SOTON/O.Q. 3101262    7.2500   \n",
       "416    male   NaN      0      0              359309    8.0500   \n",
       "417    male   NaN      1      1                2668   22.3583   \n",
       "\n",
       "               Cabin Embarked  ticket_prefix  ticket_num_digits    title  \n",
       "0                NaN        Q            0.0                6.0      Mr.  \n",
       "1                NaN        S            0.0                6.0     Mrs.  \n",
       "2                NaN        Q            0.0                6.0      Mr.  \n",
       "3                NaN        S            0.0                6.0      Mr.  \n",
       "4                NaN        S            0.0                7.0     Mrs.  \n",
       "5                NaN        S            0.0                4.0      Mr.  \n",
       "6                NaN        Q            0.0                6.0    Miss.  \n",
       "7                NaN        S            0.0                6.0      Mr.  \n",
       "8                NaN        C            0.0                4.0     Mrs.  \n",
       "9                NaN        S            1.0                5.0      Mr.  \n",
       "10               NaN        S            0.0                6.0      Mr.  \n",
       "11               NaN        S            0.0                3.0      Mr.  \n",
       "12               B45        S            0.0                5.0     Mrs.  \n",
       "13               NaN        S            0.0                5.0      Mr.  \n",
       "14               E31        S            1.0                4.0     Mrs.  \n",
       "15               NaN        C            1.0                4.0     Mrs.  \n",
       "16               NaN        Q            0.0                6.0      Mr.  \n",
       "17               NaN        C            0.0                4.0      Mr.  \n",
       "18               NaN        S            1.0                7.0    Miss.  \n",
       "19               NaN        C            0.0                4.0     Mrs.  \n",
       "20               NaN        C            1.0                5.0      Mr.  \n",
       "21               NaN        S            1.0                5.0  Master.  \n",
       "22               NaN        S            1.0                5.0     Mrs.  \n",
       "23               NaN        C            1.0                5.0      Mr.  \n",
       "24   B57 B59 B63 B66        C            1.0                5.0     Mrs.  \n",
       "25               NaN        S            1.0                4.0      Mr.  \n",
       "26               B36        C            0.0                6.0    Miss.  \n",
       "27               NaN        C            0.0                4.0      Mr.  \n",
       "28               A21        S            0.0                6.0      Mr.  \n",
       "29               NaN        C            0.0                4.0      Mr.  \n",
       "..               ...      ...            ...                ...      ...  \n",
       "388              NaN        Q            0.0                6.0      Mr.  \n",
       "389              NaN        S            0.0                6.0  Master.  \n",
       "390              B24        S            0.0                5.0      Mr.  \n",
       "391              D28        S            1.0                5.0     Mrs.  \n",
       "392              NaN        S            1.0                4.0  Master.  \n",
       "393              NaN        S            1.0                5.0      Mr.  \n",
       "394              NaN        S            0.0                6.0      Mr.  \n",
       "395              C31        S            0.0                5.0     Mrs.  \n",
       "396              NaN        Q            0.0                6.0      Mr.  \n",
       "397              B41        C            0.0                5.0     Mrs.  \n",
       "398              NaN        S            0.0                6.0      Mr.  \n",
       "399              NaN        Q            0.0                5.0      Mr.  \n",
       "400               C7        S            0.0                5.0    Miss.  \n",
       "401              NaN        S            0.0                5.0      Mr.  \n",
       "402              NaN        C            0.0                6.0    Miss.  \n",
       "403              NaN        S            0.0                6.0      Mr.  \n",
       "404              D40        C            0.0                5.0      Mr.  \n",
       "405              D38        C            1.0                4.0      Mr.  \n",
       "406              NaN        S            0.0                5.0      Mr.  \n",
       "407              C80        C            0.0                6.0      Mr.  \n",
       "408              NaN        Q            0.0                6.0    Miss.  \n",
       "409              NaN        S            1.0                7.0    Miss.  \n",
       "410              NaN        Q            0.0                6.0    Miss.  \n",
       "411              C78        Q            0.0                5.0     Mrs.  \n",
       "412              NaN        S            0.0                6.0    Miss.  \n",
       "413              NaN        S            1.0                4.0      Mr.  \n",
       "414             C105        C            1.0                5.0    Dona.  \n",
       "415              NaN        S            1.0                7.0      Mr.  \n",
       "416              NaN        S            0.0                6.0      Mr.  \n",
       "417              NaN        C            0.0                4.0  Master.  \n",
       "\n",
       "[418 rows x 14 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pass_ids = test_data.PassengerId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>897</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>898</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>899</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>900</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>901</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>903</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>904</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>905</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>906</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>907</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>908</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>909</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>910</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>911</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>912</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>913</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>914</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>915</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>916</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>917</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>918</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>919</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>920</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>921</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>1280</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>1281</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>1282</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>1283</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>1284</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>1285</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>1286</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>1287</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>1288</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>1289</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>1290</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>1291</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>1292</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>1293</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>1294</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>1295</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>1296</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>1297</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>1298</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>1299</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>1300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>1301</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>1302</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>1303</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>1304</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived\n",
       "0            892         0\n",
       "1            893         0\n",
       "2            894         0\n",
       "3            895         1\n",
       "4            896         0\n",
       "5            897         0\n",
       "6            898         0\n",
       "7            899         0\n",
       "8            900         1\n",
       "9            901         0\n",
       "10           902         0\n",
       "11           903         0\n",
       "12           904         1\n",
       "13           905         0\n",
       "14           906         1\n",
       "15           907         1\n",
       "16           908         0\n",
       "17           909         0\n",
       "18           910         1\n",
       "19           911         0\n",
       "20           912         0\n",
       "21           913         1\n",
       "22           914         1\n",
       "23           915         0\n",
       "24           916         1\n",
       "25           917         0\n",
       "26           918         1\n",
       "27           919         1\n",
       "28           920         0\n",
       "29           921         0\n",
       "..           ...       ...\n",
       "388         1280         0\n",
       "389         1281         0\n",
       "390         1282         0\n",
       "391         1283         1\n",
       "392         1284         1\n",
       "393         1285         0\n",
       "394         1286         0\n",
       "395         1287         1\n",
       "396         1288         0\n",
       "397         1289         1\n",
       "398         1290         0\n",
       "399         1291         0\n",
       "400         1292         1\n",
       "401         1293         0\n",
       "402         1294         1\n",
       "403         1295         0\n",
       "404         1296         0\n",
       "405         1297         0\n",
       "406         1298         0\n",
       "407         1299         0\n",
       "408         1300         1\n",
       "409         1301         1\n",
       "410         1302         1\n",
       "411         1303         1\n",
       "412         1304         0\n",
       "413         1305         0\n",
       "414         1306         1\n",
       "415         1307         0\n",
       "416         1308         0\n",
       "417         1309         1\n",
       "\n",
       "[418 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df = pd.DataFrame({'PassengerId' : pass_ids, 'Survived' : test_predictions})\n",
    "submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission_df.to_csv(\"../../datasets/titanic/submission1.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
